# MySQL

## MySQL的体系结构

- 数据库连接池（认证、线程复用、连接限制、内存检查、内容缓存等）
- 数据库管理服务和工具组件（备份、恢复、主从复制、集群、安全管理、配置、数据迁移等）
- SQL接口（DML、DDL、存储过程、视图、触发器）组件
- 查询解析器组件：解析验证查询语句，判断语法是否正确（拥有查询缓存，如果具有某个查询的缓存数据，直接返回，不再去进行查询）
- SQL优化器组件：对SQL语句进行改写和优化，生成最优执行计划
- 数据库缓存、缓冲组件
- 数据库存储引擎（MySQL很多种的存储引擎，常用的InnoDB、MyISAM等）
- 物理文件（磁盘上存储的内容）

![MySQL 体系结构及存储引擎_殷建卫-程序员信息网- 程序员信息网](https://gitee.com/Jia_bao_Li/img/raw/master/img/MySQL%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E5%9B%BE.png)



## MySQL存储引擎的比较

| 特性           | MyISAM | InnoDB | Memory | archive   | NDB    | RDB    |
| -------------- | ------ | ------ | ------ | --------- | ------ | ------ |
| 存储限制       | 无     | 64TB   | 有     | 无        | 有     | 无     |
| 事务支持       | 不支持 | 支持   | 不支持 | 不支持    | 不支持 | 支持   |
| 锁粒度         | 表级锁 | 行级锁 | 表级锁 | 行级锁    | 行级锁 | 页级锁 |
| 多版本并发控制 | 不支持 | 支持   | 不支持 | 支持      | 支持   | 不支持 |
| B树索引        | √      | √      | √      |           | √      | √      |
| 哈希索引       |        | √      | √      |           | √      |        |
| 全文搜索索引   | √      |        |        |           |        |        |
| 集群索引       |        | √      |        |           |        |        |
| 数据缓存       |        | √      | √      |           | √      |        |
| 索引缓存       | √      | √      | √      |           | √      |        |
| 数据压缩       | √      |        |        | √         |        |        |
| 数据加密支持   | √      | √      | √      | √         | √      | √      |
| 存储开销       | low    | High   | N/A    | very low  | low    | low    |
| 内存开销       | low    | High   | Medium | Low       | High   | low    |
| 批量插入速度   | High   | Low    | High   | Very High | High   | High   |
| 支持外键       |        | √      |        |           |        |        |
| 主从支持       | √      | √      | √      | √         | √      | √      |
| 查询缓存支持   | √      | √      | √      | √         | √      | √      |
| 备份恢复       | √      | √      | √      | √         | √      | √      |



### InnoDB引擎的逻辑存储结构

![InnoDB逻辑存储结构](https://gitee.com/Jia_bao_Li/img/raw/master/img/InnoDB%E9%80%BB%E8%BE%91%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84.png)



### InnoDB和MyISAM的区别

**InnoDB：**

- 面向（OLTP在线事务处理）方面的应用
- InnoDB支持行锁、外键、事务、多版本并发控制的读写
- InnoDB支持列的自增属性
- InnoDB读效率低于MyISAM，写效率略高于MyISAM
- InnoDB的批量插入比MyISAM慢
- 表数据和索引文件.idb，表结构定义.frm
- InnoDB适合频繁修改、安全性较高的应用中
- 清空表的时候，InnoDB是一行一行删除数据
- 5.5.8之后官方默认使用的存储引擎

**MyISAM：**

- 面向OLAP（Online Analytical Processiong在线分析处理）应用
- 支持表锁
- 支持全文索引
- 表由.myd数据文件和.myi索引文件组成，表结构定义.frm
- MyISAM只会缓存索引文件，对于数据文件缓存交给操作系统
- 适合查询以及插入为主的应用
- 清空整个表，MyISAM会新建表
- 5.5.8之前官方使用的存储引擎

-------------------------------------------------------

## MySQL的事务

### 事务的特性

- 原子性：事务的操作要么都成功，要么都失败，不存在某一个操作成功其他操作失败
- 一致性：执行读取事务前后，数据保持一致多个事务对数据的读取操作获取的结果都是一致的
- 隔离性：不同事务之间的操作相互隔离不会相互影响
- 持久性：数据库事务的操作一旦提交，对数据的更改是永久的，数据库崩溃都不能改变

### ACID保证？

- 原子性：undolog日志来保证的，undolog日志记录了需要回滚的日志信息，一旦事务 需要回滚，可以借助日志回滚之前成功的命令
- 隔离性：MVCC，多版本并发控制来保证，通过版本号cas
- 持久性：利用redolog日志来保证，命令执行都是先写日志再执行，就算命令执行不成功，还可以借助redolog的日志信息恢复之前没有执行成功的命令恢复数据
- 一致性：通过其他三大特性的共同保证来实现的

### 事务在并发下出现的问题

- 脏读：两个事务，一个事务在前一个 事务在后，后面执行的事务读取到的是前面事务还未提交的数据，也就是脏数据，如果事务发生回滚，则之前读取的数据是错误数据，就会导致不一致问题（不满足一致性要求）
- 幻读：事务相同查询条件读取以前检索的数据，发现查出的数据增加或者删除了某些数据的情况（不满足隔离性）
- 不可重复读：指的是在一个事务内，多次对同一个数据的读取得到结果不一样（事务A读取到事务B修改提交的数据）（不满足隔离性要求）
- 丢失更新：后一个事务覆盖了之前事务所做的修改

### MySQL事务的隔离级别

- 读未提交(read uncommitted)：不能解决并发下事务的问题，可以读取其他事务还未提交的数据。
- 读已提交(read committed)：可以解决脏读问题。只能读取其他事务提交之后的数据
- 可重复读(repetable read)：可以解决脏读和不可重复读，InnoDB借助多版本并发控制实现可重复读，解决了幻读
- 可串行化(serializable)：可以解决所有的并发问题。直接对数据加锁来解决这些问题

隔离级别的查看和设置：

- 查看：`select @@transaction_isolation`查看隔离级别
- 设置：`set session tranaction isolation level read committed;`

### MVCC多版本并发控制

同一份数据保留多个版本的方式，借助这个来实现并发控制。

查询的时候，通过`read view`和版本链来找到对应版本的数据

作用：提升并发性能，在并发场景下，mvcc比行级锁的开销更小

#### 实现原理

版本链：通过表中三个字段来实现

- `DB_TRX_ID`：当前事务ID，通过事务的ID来区分事务的先后顺序
- `DB_ROLL_PRT`：回滚指针，指向当前行记录的上一个版本，通过这个指针构成了`undo log`的版本链
- `DB_ROW_ID`：主键

版本链生成的过程：

1. 使用排他锁锁住当前行
2. 将该行的原本值拷贝到`undo log`，作为旧版本的数据用来进行回滚
3. 修改当前行的数据，生成一个新版本，更新事务ID，回滚指针指向旧版本记录

`read view`：数据在每一个 时刻的状态的记录。获取某个时刻的记录，就去对应时间点下的`read view`查找。`read view`内部维护一个活跃的事务链表，表示生成`read view`的时候还在活跃的事务，包含了创建`read view`还未提交的事务，不包含创建之后提交的事务。

- `DATA_TRX_ID`：每个数据行的最新的事务ID
- `UP_LIMIT_ID`：表示当前快照中的最先开始的事务ID
- `LOW_LIMIT_ID`：表示当前快照中的最慢开始的事务ID

两个隔离级别下创建`read view `的时机：

- `read committed`：每次执行select都会创建新的`read view`保证可以读取到其他事务已经提交的修改
- `repeatable read`：在一个事务范围内，第一次select时更新，之后不会再更新，后续的所有select都是复用，后续的select都是复用之前的`read view`，借此来保证事务范围内每一次读取都会一样

如何根据`read view`中的数据来判断事务的可见性？

- `DATA_TRX_ID < UP_TRX_ID`：说明当前数据的事务在快照之前就已经提交了，因此数据对当前的快照是可见的
- `DATA_TRX_ID >= LOW_LIMIT_ID`：说明当前数据的事务比快照开启的晚，因此该数据对当前快照是不可见的，需要通过版本链回溯到前面一个版本再次进行判断
- 处于两者之间的：查找活跃事务链表中是否存在ID为`DATA_TRX_ID`的事务
  - 存在，因为活跃事务链表中的数据未提交，因此是不可见的，需要通过版本链来找寻上一版本
  - 不存在，说明事务已经提交，这行记录是可见的

### 快照读和当前读

快照读：读取的是快照版本。普通的select方式就是快照读，快照读通过mvcc来实现并发控制，不用进行加锁

当前读：读取的是最新版本，`update、delete、insert、select ... lock in share mode、select ... for update`，这些操作都是当前读

快照读通过mvcc来保证避免幻读的问题，但是当前读下并不能避免，因为当前读都是读的新数据，如果两次读取之间发生了数据的修改，那么就会产生幻读。

MySQL避免幻读的方式：

- 快照读情况下，通过mvcc来避免幻读
- 在当前读的情况下，通过`next-key`来避免幻读（加行锁和间隙锁来实现）

`next-key`包括两部分：行锁和间隙锁。

- 行锁加在索引上的锁
- 间隙锁加在索引之间

`Serializable`隔离级别也可以避免幻读，但是性能极低

---------------------------------------

## MySQL的日志

### 错误日志

记录了MySQL的启动、运行、关闭过程的一些状况，这个文件一般记录了所有的错误信息，除此之外，还记录了一些警告信息或者正确的信息。

定位该日志文件可以使用命令：`show variables like 'log_error'`查看日志文件的位置

如果服务器启动的时候出现了问题，应该查看错误日志来寻找帮助

### 事务日志

#### Undo log

事务开始之前，操作任何数据之前，需要先将需要操作的数据备份到一个地方

作用：

- 回滚数据：程序发生异常错误，根据undo log可以回滚到事务之前的数据状态，保证原子性
- MVCC一致性视图：通过undo log找到对应的数据版本号，保证MVCC视图一致性的必要条件

#### Redo log

事务的执行过程中，开始写入redo log。防止发生故障的时间点，尚有脏页未写入磁盘，重启MySQL服务，根据redo log重做，完成事务未入磁盘数据的持久化

作用：

- 前滚操作：具备崩溃恢复能力，提供断电重启解决事务丢失数据的问题，保证数据的持久化
- 提高性能：先写redo log记录更新，当有空闲线程时再去执行，redo log满了会进行刷脏，写redo log顺序写，刷脏堆积写

### BinLog日志

二进制日志：这个日志记录了对MySQL数据库执行更改的所有操作，但是不包括select和show操作。但是如果操作并没有影响数据库的数据也会被写入日志中。

二进制日志的功能作用：

- 恢复：有些数据的恢复需要借助二进制日志来完成
- 复制：可以让远程数据库和某台MySQL数据库之间保持数据同步，主从同步的实现需要记住二进制日志
- 审计：借助二进制日志分析外来请求，查询是否存在SQL注入

二进制日志记录的格式：`binlog_format`

- statement：语句级别，只记录更改数据库操作的语句
- row：记录更改数据之后的具体数据内容
- mixed：两种机制的综合，当存在uuid、date等操作的时候，记录row，记录下具体的数据，防止主从不一致的情况，其他不同机器不同时间执行都不会有变化的就可以记录为statement，只需记录语句，之后执行语句即可完成同步恢复

max_binlog_size：记录单个二进制日志文件的最大值，默认1G

### binlog和redolog的区别

- binlog记录所有的日志记录，包括各种存储引擎的日志。redolog只记录Innodb的事务日志
- binlog是逻辑日志，记录的是SQL语句的原始逻辑，redolog记录的是物理日志，记录的是某个数据页上进行的修改
- binlog只在事务提交前写入磁盘，一个事务只写一次，但是redolog在事务执行过程都会不断写入

### 日志落盘（刷写回磁盘中）策略

#### binlog持久化

每个线程都有自己 binlog cache 区域，**在事务运行的过程中，MySQL 会先把日志写到 binlog cache 中，等到事务真正提交的时候，再统一把 binlog cache 中的数据写到 binlog 文件中**。（binlog cache 有很多个，binlog 文件只有一个！）

每一个日志文件和日志文件的读写操作之间都有自己的一个page cache（充当缓存作用的一块内存，这一块内存是用来模仿CPU缓存的作用，借助这个可以缓解因读写速度差异过大导致的等待时间过长的问题）

当binlog每次从binlog缓存写入数据到日志文件的时候，都不是直接写入文件，而是先写入page cache缓存中，等到缓存中数据达到一定数量的时候，就会将这一部分缓存中的数据写入到文件中（这才是真正的落盘操作fsync）

![image-20220112133619093](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E6%97%A5%E5%BF%97%E8%90%BD%E7%9B%98%E7%9A%84%E6%B5%81%E7%A8%8B.png)

上面的write和fsync操作的具体时间，通过`sync_binlog`参数来设置：

- `sync_binlog=0`，每一次提交事务的时候，只进行write，不进行fsync的操作
- `sync_binlog=1`，每一次提交事务的时候，执行write和fsync
- `sync_binlog=n`，每次提交事务，只执行write，等到积累了n个事务的时候，执行一次fsync

#### redolog持久化

redolog事务执行过程中，类似于binlog，redolog也存在类似缓存的内存区域，称为redolog buffer（进程中只有一个redolog buffer）

在事务执行过程中，MySQL会先把日志写入到redolog buffer中，等到事务真正提交的时候，再统一把redolog buffer中的数据写入日志文件中。不过这个写入日志文件的过程也是和binlog落盘策略一样，先将buffer中的数据写入到page cache中，最后执行fsync才是真正的将数据写入到日志文件中。

![image-20220112134730150](https://gitee.com/Jia_bao_Li/img/raw/master/img/redolog%E8%90%BD%E7%9B%98%E7%AD%96%E7%95%A5.png)

redolog写入策略的控制参数：InnoDB中有一个`innodb_flush_log_at_trx_commit`参数:

- `innodb_flush_log_at_trx_commit=0`：每次事务提交时，只是将事务redolog日志保存在redolog buffer中
- `innodb_flush_log_at_trx_commit=1`：每次事务提交时，执行fsync将redolog持久化到磁盘
- `innodb_flush_log_at_trx_commit=2`：每次事务提交时，只执行write将日志写入到文件系统中的page cache中

#### 为什么事务还没提交，redolog日志也可能被持久化？

- InnoDB后台有一个线程，每隔1秒进行一次轮询：调用write将redolog buffer中的日志写入到文件系统的page cache，然后调用fsync将日志持久化到磁盘。如果在事务执行的时候，有日志被写入到redolog buffer中，可能会被这个后台线程给刷入磁盘中的
- 并发事务导致：当某个事务提交（刷盘策略是1，每次提交都进行刷盘操作），执行fsync进行刷盘的时候，是可能将其他事务的redolog buffer日志文件刷入到磁盘中的
- redolog buffer的占用空间占用了redolog buffer内存大小（`innodb_log_buffer_size`控制，默认8MB）的一半，后台线程主动进行写盘（写入文件系统的page cache）不过还在内存中，并没有fsync写入磁盘。

由于上面的策略，redolog存在三种状态：

- 事务执行过程中，redolog写入到了redolog buffer中
- 事务提交，redolog从redolog buffer通过write写入到page size，但是还未执行fsync提交到磁盘
- 事务提交，并执行了fsync刷入到磁盘

------------------------------------------

## 索引

### B树

让每一个二叉树结点多存放一些数据，这样每次IO读取更多的数据，减少磁盘的IO

优点：

- 优秀的检索速度：时间复杂度O(hlog(n))
- 尽可能少的IO，增加检索速度
- 支持范围查找

![image-20210924202102202](https://gitee.com/Jia_bao_Li/img/raw/master/img/B%E6%A0%91.png)

### B+树

相比B树，B+树：

- 结点存放的是索引（地址），所以B树里面一个节点存不了很多数据，B+树可以存储很多个索引，B+树叶子节点存储所有的数据
- B+树的叶子节点是用链表串联起来，方便范围查找

![image-20210924202036713](https://gitee.com/Jia_bao_Li/img/raw/master/img/B+%E6%A0%91.png)

B+树为了在数据插入删除过程中保持平衡，需要进行旋转操作或者页的拆分来保证树的平衡。

叶子节点的分页操作实际上需要磁盘的操作，而为了保证效率就需要尽量保证少出现叶子节点的拆分，因此B+Tree一般先通过旋转来进行树的平衡，当通过旋转不能达到树的平衡就需要进行叶子节点的拆分来保证树平衡

B+树索引在数据库中有一个特点高扇出性，因此数据库中，B+树的高度一般都只是2-4层，因此一般只需要2-4次IO即可找到需要的数据页，效率还是很可观的

数据库中的B+树索引可以分为聚集索引和辅助索引

### 添加索引的时机

并不是所有查询条件中出现的列都需要添加索引，一般经验：

- 查询的时候只访问表的很少一部分内容时，使用索引才更有意义
- 对于低选择性的列，比如性别字段，可选择范围小，因此每次筛选之后还有比较大数据量，这一类的列设置索引的带来的性能并不高
- 对于高选择性的字段列，创建索引是比较合适的
- 需要用来联表的列可以创建索引加快联表效率

如何判断一个列是否具有高选择性？

通过每个表的show index命令查看索引中数据的Cardinality的值大小来判断，这个数值是一个记录索引中不重复记录数量的预估值，如果这个数值和总记录数的比值很小远小于1的话，就需要考虑是否还有必要创建这个索引。这个值应该尽可能的接近1

数据库如何统计的Cardinality数值？

为了防止数据量大的时候统计这个值负载太大，通过采样法来获取这个数值，因此这个数值是预估值。

InnoDB引擎中，Cardinality的统计信息更新发生在insert和update这个两个操作。此外对于Cardinality的更新，考虑到大数量下的更新可能对系统造成较大负载，因此采用了一定条件下才触发Cardinality的更新：

- 表中的1/16的数据发生过变化；发生变化的数据量的占比
- stat_modified_counter>2000000000；数据发生变化的次数

信息统计和更新的具体流程（采样）：

- 取得B+树索引叶子节点数量，A
- 随机取得B+树索引的8个叶子节点，统计每个页中不同记录的个数，记为P1，p2...P8
- 进行采样信息估算Cardinality信息：Cardinality=(P1+P2+...+P8)/8*A

### 索引高级技巧

#### 索引的优缺点

优点：

- 可以加快查询的效率
- 索引还可以加快排序分组的效率
- 加快表表之间的连接效率
- 可以借助数据库的查询优化器来对数据查询进行优化

缺点：

- 维护索引的开销：维护更新索引需要耗费时间
- 索引存储需要占据一定空间

#### 创建索引的注意点

- 索引列最好设置为非空：因为MySQL中含有空值的列 很难进行查询优化，空值的存在导致索引统计和比较运算变得复杂，对于空值可以采用0，空串或者特殊值来替代
- 索引一般需要选择那些数据离散性大选择性较好的字段，像性别这一类选择性不好的列，不适合创建索引
- 索引字段数据量不要太大：太大的维护索引困难，此外可能导致IO次数变多，数据量少的时候一次IO可以读取到更多的索引
- 索引要满足最左匹配原则
- 索引列不能参与计算，计算会导致索引失效
- 尽量扩展索引，不要新建索引。索引数量过多也是会导致数据库性能的下降

#### 使用索引一定提高查询性能嘛?

- 索引的维护需要耗费空间和时间的，数据的新增都会导致索引的变更，因此需要适度使用索引
- 如果创建的索引并不合适，并不能带来想要的优化，反而带来了额外的维护开销，得不尝失
- 索引范围查询的时候一般适合那些查询数据量只占一小部分的数据30%左右，如果使用索引查询了很多的数据，有的时候可能甚至比没有索引查询还要慢

#### 聚集索引

聚集索引：按照每个表的主键来构造一颗B+树，同时叶子节点中存放的是整张表的记录数据，聚集索引的叶子节点也称之为数据页。聚集索引能够直接在叶子结点上找到数据，此外可以根据数据的逻辑顺序快速定位某个范围值的查询。查询优化器可以借助聚集索引快速发现某一段的数据页需要扫描

聚集索引对于主键的排序查找和范围查找都非常的快，因为叶子节点存储的数据就是用户所需要查找的数据，只需要查询到索引位于的叶子结点就能立马获取到查询的数据

一般聚集索引都是主键索引，如果没有主键索引，会选择第一个不为null的唯一索引，如果还没有就会自己创建一个隐藏的主键，隐藏主键六个字节，也是自增的，官方建议自己创建一个主键索引（唯一非空索引）

#### 为什么官方建议使用自增主键作为聚集索引？

根据B+Tree索引的特点，自增主键的连续性，可以保证插入过程中尽量减少页的分裂，减少IO的次数提高效率。

使用自增主键作为索引的优点：

- 进行页分裂的次数很少，只会分裂很少一部分。
- 可以减少数据的移动，每次插入都是插入到最后

#### 自增主键一定连续递增嘛

不是，导致主键不连续递增的情况：

- 事务执行之后的事务回滚，导致主键不连续（事务下混滚auto_increment会出现问题，而维护有比较耗费时间精力，因此干脆就不进行回滚，牺牲一部分的连续）
- 唯一索引冲突导致的主键不连续（分配了主键并且auto_increment已经变化，这种情况下，出现唯一索引冲突导致数据插入失败，但是这时候auto_increment已经增加了不会回滚）



#### 辅助索引

回表查询，指的是根据非聚集索引查询到主键索引之后，再根据查询到的主键去查询详细数据的这一过程。

辅助索引：叶子节点不包含行记录的全部数据，除了包含键值之外，每个叶子节点的索引行中包含了一个bookmark，用来告知InnoDB哪里可以找到与该索引相关的行数据。InnoDB的辅助索引中的bookmark就是指向行数据所对应的聚集索引

辅助索引的存在并不影响在聚集索引中的数据安排，因此每张数据表可以存在多个辅助索引。借助辅助索引首先查询到对应的叶子节点，然后读取叶子节点上的bookmark（也就是聚集索引所在的位置），然后查询一次聚集索引，才能最终获取到对应的行数据

#### 联合索引

联合索引：指对表上的多个列进行索引，创建的时候指定索引名之后，后面接着指定多个列即可创建联合索引

使用联合索引的时候需要满足最左匹配原则，不然可能出现索引失效的问题

#### 覆盖索引

覆盖索引：从辅助索引中获取到想要查询的记录，而不需要查询聚集索引中的记录。

覆盖索引的优点：

- 辅助索引不包含整行信息，因此远小于聚集索引，因此可以减少IO操作
- 辅助索引对于统计问题，可以带来更好的性能，统计数据的时候，优化器会优先使用辅助索引来进行统计（count(*)和count(无索引列)和count(主键)）效率，主键和使用索引的效率接近，count无索引列的效率最低

#### 最左匹配原则

创建队列索引的时候，索引使用的时候一定要按照最左匹配原则来使用，不然可能出现索引失效的情况。

原则：

- where子句中使用比较频繁的列放在最左边
- mysql的条件会持续直到遇见范围查找（><、between like）等就会停止索引的匹配
- 非范围查找的索引列可以放到前面进行查询，不然可能导致后面的精确查询并未能够走索引
- =和in的查找顺序可以随便排列

#### 前缀索引

当某一列的数据比较长的时候，但是又需要使用该列的索引时候，可以考虑创建前缀索引，只把很长字段的前面的公共部分作为一个索引，可以获取很好的效益，不过order by不支持前缀索引。

创建前缀索引的流程：

- 首先计算列的选择性：`select count (distinct col_name)/count(*) from table_name`
- 再去计算不同前缀长度下的列的选择性：`select count(distinct left(col_name,4))/count(*) from table_name`
- 找到一个比较合适的前缀长度之后，就可以根据这个最优长度来建立索引了
- 建立前缀索引：`create index idx_front on table_name (col_name(length))`

#### 使用强制索引

查询中如果确定走某个索引效率更好，可以采用`FORCE INDEX (idx_xxx)`命令强制使用索引查询

#### 使用索引提示

支持索引提示（INDEX HINT），显式的告知优化器使用哪一个索引。

使用索引提示的场景：

- MySQL的优化器错误的使用了某个索引，导致SQL运行较慢。但实际上大部分情况优化器都工作的很有效和正确
- 某个SQL语句可以选择的索引非常多，这时候优化器执行计划时间（explain）的开销可能大于SQL本身

在命令中使用`USE INDEX (idx_xxx)`，虽然指定了索引，但是最终优化z'z's'sa器会不会选择该索引还是得看优化器。

虽然你建议，但是我不一定听

但是如果使用force指定，就会按照指定的索引进行查询

#### Multi-range Read优化

5.6版本之后支持MRR优化，目的是为了减少磁盘的随机访问，将随机访问转化为较顺序的数据访问，这个优化适用于explain计划查询中type为range、ref、eq_ref的类型的查询。如果使用这个优化在extra的信息可以看到`Using MRR`

MRR优化的优点： 

- 使得数据的访问变得较为顺序，在查询辅助索引时，首先根据得到的查询结果，按照主键进行排序，并按照主键排序的顺序进行书签的查找
- 减少缓冲池中页被替换的次数
- 批量处理对键值的查询操作

MRR工作方式：

- 将查询到的辅助索引值放入一个缓存中，缓存中的值是按照辅助索引键值排序的
- 将缓存中的值按照主键RowID（聚集索引）进行排序
- 根据RowID的排序顺序来访问实际的数据
- 如果缓冲池不是足够大，不能存放下一张表的所有数据，频繁的离散读的操作可能导致缓冲池中页被替换出缓冲池，之后又被读入缓冲池，如果按照主键顺序读，可以降低这种频繁替换写入的情况，提高效率

开启MRR优化读的命令：`SET @@optimizer_switch='mrr=on,mrr_cost_based=off';`

控制键值缓冲区大小的参数：`read_rnd_buffer_size`，默认256K

查看键值缓冲区的大小：`SELECT @@read_rnd_buffer_size`

#### Index Condition Pushdown（ICP）优化

5.6之后支持的根据索引进行查询的优化方式，MySQL会在取出索引的同时，判断是否可以进行where条件的过滤，也就是将where的部分条件的过滤操作放在了存储引擎层，某些情况下，可以大大减少上层SQL层对记录的索取，从而提高数据库的整体性能。这个又被叫做索引下推

这个优化支持range、ref、eq_ref、ref、ref_or_null类型的查询，执行了`index_condition_pushdown`优化会在extra看到`using index condition`的提示

使用了这个优化的特点：

- 在索引被取出的时候，就会进行where条件的过滤，然后再去获取记录
- 可以减少回表的次数，InnoDB中只针对二级索引生效

索引下推例子：创建了二级索引（zipcode,lastname,firstname），查询语句`select * from people where zipcide='134' and lastname like "djan%" and address like "Main street%" `:

- 使用了索引下推，首先查找到满足索引zipcode=‘134’的索引记录，然后根据筛选条件来判断是否满足条件，满足条件才会进行回表 查询，否则直接抛弃
- 没有使用下推的，查找到满足条件的134索引记录之后，直接在存储引擎中直接查询记录，然后再进行筛选条件的判断

将这个优化和MRR优化同时开启可以提升极大的性能，接近好几倍

### 索引失效的情况

- **不满足最左匹配原则**：当一个索引存在多个索引的时候，一定要保证最左边的索引一定存在，不然可能存在索引失效的情况。还有在创建联合索引的时候，创建顺序最好按照索引字段的左右顺序指定，不然会出现一些问题）
- **使用了`select *`进行查询**，可能会导致索引失效。覆盖索引：指当前查询的列都是索引列的话，那么随便根据列中的哪一个索引查询都会走索引查询，效率会更高。select *大概率不会是走的覆盖索引，因此可能存在索引失效的情况
- **索引列存在计算**：会导致索引失效
- **索引列存在函数运算**：会导致索引失效
- **字段类型不一致**：当传给索引的值类型和索引的类型不匹配的话，也可能导致索引失效。比如int类型传递给varchar类型就会出现索引失效，但是如果索引类型是int，传入的是字符类型的数据的时候，不会导致索引失效
- **like的最左边包含有%通配符**：如果你的like的表达式的最左边包含有%，最终会导致你的索引失效
- **和其他列进行了对比**：索引也会实现，尽管类型一致都有索引也会导致最终查询不走索引
- **使用or关键**：如果使用了or关键字，那么你的条件中的所有相关列都需要创建了索引才可以
- **范围查询**：in、exists都会走索引，但是not  in和not exists都不会走索引
- **order by的某些情况也不会走索引**：order by不加where或者limit、不满足最左匹配原则、多种排序原则共存、对不存在索引的列做order by

### 自适应哈希索引

InnoDB引擎有一个特殊功能：自适应哈希索引，当InnoDB引擎注意到某些索引值使用得非常频繁时，会在内存中基于B-Tree索引之上创建一个哈希索引，让B-Tree索引具有哈希索引的优点(快速哈希查找)。这个自适应哈希是一种自动、引擎内部的行为，用户无法控制配置，只能选择开启或者关闭这个功能

### 全文检索

全文检索：将存储于数据库中的整本书或者整篇文章中的任一内容查找出来的一种技术，可以获取到文章中相关关键词或者章节的信息，也可以进行各种统计和分析。

最开始的InnoDB并不支持全文索引，MyISAM支持全文索引，不过从InnoDB的1.2.x版本开始，InnoDB也支持全文检索

倒排索引：在辅助表中存储了单词与单词在文章中所处的位置的一个映射，通常借助关联数组实现

- inverted file index：单词：单词所在的文档
- full inverted index：单词：（单词所在文档，文档中的具体位置）

倒排索引的关键在于如何进行分词，英文还比较方便，根据空格分词然后统计单词的次数和位置，对于中文，还需要选择合适的分词算法才能够保证倒排索引的正确性

---------------------------------------------

## InnoDB的锁

### 锁类型

InnoDB的两种行级锁：

- 共享锁（S Lock）：允许一个事务读一行数据
- 排他锁（X Lock）：允许事务删除或更新一行数据

意向锁：将锁定的对象分为多个层次，意向锁意味着事务希望在更细粒度进行加锁，如果想要对细粒度加锁，首先需要对粗粒度对象上锁。如果需要对某一个页上的记录进行上锁，首先会对数据库的这一个页进行上锁，然后再对记录进行行级锁的设定

- 意向共享锁（IS Lock）：事务想要获取表中某几行的共享锁
- 意向排他锁（IX Lock）：事务想要获取表中某几行的排他锁

infomation_schema数据库下的INNODB_TRX、INNODB_LOCKS、INNODB_LOCK_WAIT三张表，可以用来监控当前事务并分析可能存在的锁问题

### 一致性非锁定读

借助多版本控制的方式来读取当前执行的数据库中行的数据，如果读取的行正在执行delete或者update操作，这时候的读操作不会因此等待行锁的释放，而是从存储引擎中读取一份快照数据。

非锁定读的机制可以很好的提高数据库的并发性，这是InnoDB的默认设置的读取方式，读取不会占用和等待表上的锁。不过对于不同隔离级别，InnoDB设置的读取快照数据的版本不同。在ReadCommited隔离级别下，读取的是锁定行的最新数据，而在Repeatable Read隔离级别下，读取的总是事务开始时的行数据版本。

多版本并发控制：指在并发下不同时间有不同行数据版本，针对这种状况下的并发控制，称为多版本并发控制

验证可以开启两个事务，然后分别设定在不同事务隔离级别下的情况：

- 开启事务A，查询id=1的记录
- 开启事务B修改id=1的记录为id=3
- 事务B提交修改
- 事务A中继续查询i的记录，这个时候就会发现在两个不同级别得到的结果不一样

### 一致性锁定读

某些情况下，可能需要保证查询的数据一致性，需要对查询操作进行加锁，这种就是一致性锁定读，即使是读操作，也进行加锁操作：这两个语句需要在事务中执行，事务结束，锁也就释放了

- select .. for update :加的是X锁
- select ... lock in share mode：加的是S锁

### 自增长和锁

对于自增的主键数据的插入，会采用一种自增长锁机制，提高插入的性能（不用等待事务结束才释放锁，只要主键行数据插入后立即释放）

### 锁算法

- Record Lock：单个行记录上的锁
- Gap Lock ：间隙锁，锁定一个范围但不包含记录本身
- Next-key Lock：前两种锁的结合，锁定一个范围并锁定记录本身（解决幻读设计的）

-------------------------------

## 主从同步

主从机制一般用来做读写分离，写请求会发送到主机，读请求指派到从机上。

读写分离主要是用来减轻主数据库的查询压力，此外并发读并不会影响查询结果，因此不用采用同步措施来保证，将读和写分离可以在高并发的时候大大降低并发下读写的压力。

读写分离的另外一个操作就是主库可以不建立查询的索引，从库建查询的索引

### 读写分离具体实现

#### 代码层面

代码抽取中间层，借助这一层的代码来进行读写分离和数据库连接。

做一个代理类，将暴露的读写接口进行封装，将读指向从数据库，写指向主库

优点：

- 简单，可以根据业务定制变化

缺点：

- 如果数据库发生变更，代码可能需要进行修改之后重启服务
- 不同的场景可能要写很多份的代码

#### 中间件

将主从的机制交给另外一个系统来做，客户端只需要和这个系统进行交互即可

优点：

- 可以屏蔽底层的细节，屏蔽语言的差异，看起来好像只和一个数据库进行交互一样

缺点：

- 额外增加了一层中间件进行交互，多了一个系统需要维护，可靠性下降
- 此外这个中间件有可能成为性能瓶颈

### 主从同步实现

借助binlog来进行的主从同步，对数据库的更改操作都会被写入到binlog日志文件中，主从数据库之间只需要交互binlog文件就可以实现数据的同步。

默认的同步是采用的异步复制，具体的流程：

主库：

- 接收事务请求
- 更新数据
- 将更新的数据写入到binlog中
- 给客户端响应事务结果
- 将binlog日志推送给从从库

从库：

- 将IO线程同步的binlog写入relay log
- 从relay log中更新数据
- 给主库响应同步结果

异步复制的问题：

- 主从同步的时候，主库更新了数据，但是binlog还未同步给从库，如果此时的主库宕机，然后某个从库晋升为主库的时候，并没有原来主库的数据，导致数据不一致

同步复制：主库将binlog复制到所有从库，等所有的从库都响应数据同步成功之后再响应客户端的请求

5.7之后的半同步复制：可以设定多少个从库响应之后才可给客户端响应数据，可以增强可靠性和数据的一致性



### 主从同步的延迟怎么解决？

主库执行写之后立马进行查询，可能由于同步操作执行的一个延迟，导致从库查询的时候没有数据，这是主从同步延迟带来的问题。

解决方案：

- 二次查询法：如果从库查询不到数据，再去主库中查询一次。比较简单，但是读的压力又回到了主数据库，此外如果被别人攻击，借助这一个漏洞，可能导致压力过大而崩溃
- 将写之后的读转移到主数据库，不够灵活
- 关键业务的读写话走主库，非关键的业务走从库

具体如何去落地的化还是需要根据具体的业务要求来进行

----------------------------------

## SQL性能优化

### 查询执行频次

`show global status like "com_%"`

### 慢查询日志

需要开启慢查询日志

永久生效之配置文件：

```ini
[mysqld]
// 定义查询时间超过多少s的算是慢查询，这里设置的是2s
long_query_time=2
// 配置日志文件
// 5.8、5.1等版本配置如下选项
log-slow-queries="mysql_slow_query.log"
// 5.5及其以上版本配置下面的内容
slow_query_log=On
slow_query_log_file="mysql_slow_query.log"

// 记录下没有使用索引的query
log_query_not_using_indexes=on

// log_output：日志存储方式。
log_output="FILE" 表示将日志存入文件，默认值是'FILE'。
log_output="TABLE" 表示将日志存入数据库，这样日志信息就会被写入到mysql.slow_log表中。
```

命令行设置：

- `set global slow_query_log=ON`：开启慢查询
- `set global long_query_time=2`：设置慢查询的时间约定
- `set global log_queries_not_using_indexes=ON`：记录没有使用索引的查询

### profile查询

查看是否支持profile：`select @@have_profiling`

查看是否开启profile：`select @@profiling`

设置开启profiling：`set profiling=1`

查看所有的SQL语句的耗时情况：`show profiles`

查看指定查询ID的情况：`show profile for query query_id`

查看指定查询的CPU情况：`show profile cpu query query_id`

### processlist

用来查看当前MySQL的运行情况，是否有压力，正在执行的SQL和事务列表、有没有慢SQL等

### 查询分析

explain的使用：查看具体的执行计划（也就是一条查询命令的具体情况）

需要重点关注的字段：

- `type`：表示MySQL在表中找到所需行的方式，也可以称为数据库访问类型
  - `ALL`：全表扫描，需要遍历全表来找到匹配行（性能最差）
  - `index`，索引全扫描，借助索引扫描全表
  - `range`：索引范围查找
  - `eq_ref`：唯一索引查找
  - `NULL`：不用访问表或者索引，直接就可以得到结果（性能最好）
- `possible_key`：查询可能使用的索引
- `key`：实际使用的索引
- `key_len`：使用索引字段的长度
- `rows`：扫描行的数量
- `Extra`：查询的额外信息
  - `using index`：覆盖索引，不需要回表查询
  - `using where`：回表查询
  - `using filesort`：需要额外的排序，不能通过索引得到排序结果

### 慢SQL的具体优化内容

索引+SQL语句优化+数据库结构优化+优化器优化+架构优化

由浅入深的逐步优化，当你的SQL语句和索引都已经使用的很完美但是效果还是不好就需要考虑到数据库的优化已经SQL优化器的改善自定义，再深入就是架构的内容了

#### 索引

- 尽量使用覆盖索引：覆盖索引的效率更高
- 组合索引一定要满足最左匹配的原则，防止索引失效
- 查询语句书写一定要避免索引失效
- 写多读少：可以选择普通索引；更新时，普通索引可以使用change buffer进行优化，减少磁盘IO，更新先写入change buffer，查询来了再讲数据读到内存进行修改
- 索引建立原则：

#### SQL语句

- 小表驱动大表：借助小表查询的数据驱动大表的快速查询

  - in：适用于左边大表，右边小表。SQL包含in时，语句会优先执行in里面的查询语句，再执行外面的查询语句

  - exists：适用于左边小表，右边大表。exists会有限执行exists左边的语句（主查询先执行）

    ```sql
    select * from order
    where user_id in (select id from user where status=1)
        
    select * from order
    where user_id in (select id from user where status=1)
    ```

- 避免`select *`：不会走覆盖索引，存在回表操作，有时候可能导致索引失效

- union all代替union：后者会进行去重，去重比较耗时

- 善用limit限制查询的数据量：限制只输出自己的想要的数据

- 增量查询：记录上次查询的情况，下一次直接从上次结束的位置继续

- 分页查询的优化：使用子查询或者借助主键自增的情况使用范围查找优化分页逻辑

  - 自增ID利用

    ```sql
    select id,name,age 
    from user where id > 1000000 limit 20;
    # 直接以上次确定的查询位置开始
    ```

  - between优化分页,索引有要求

    ```sql
    select id,name,age
    from user where id between 100000 and 1000020;
    ```

  - 索引覆盖+子查询优化

    ```sql
    // 查询偏移为100的数据，取出25条
    select ...
    from ... join ...
    where a.id >= (select id from ... order by id limit 100,1)
    order by a.id limit 25;
    // 查询便宜480000的数据，取出25条
    select ...
    from ... join ...
    where a.id >= (select id from ... order by id limit 480000,1)
    order by a.id limit 25;
    ```

  - 记住上次查询的结束位置，直接从结束位置直接开始

    ```sql
    // 100条数据查询这个多条，然后记住最后一条数据的位置，下次查询从这个位置开始
    select ...
    from ... join ...
    where a.id > 100
    order by a.id limit 25;
    
    // 480000条数据开始，上次查询的位置结束
    select ...
    from ... join ...
    where a.id > 480000
    order by a.id limit 25;
    ```

- join的表不宜过多

- 索引数量不宜过多：创建索引需要额外存储空间，且有性能损耗，阿里规范限制索引数量5个以内，单个索引字段数不超过5个

- 合适的字段类型：

  1. 能用数字类型，就不用字符串，因为字符的处理往往比数字要慢。
  2. 尽可能使用小的类型，比如：用bit存布尔值，用tinyint存枚举值等。
  3. 长度固定的字符串字段，用char类型。
  4. 长度可变的字符串字段，用varchar类型。
  5. 金额字段用decimal，避免精度丢失问题。

- insert语句优化

  - 多插入语句合一：批量插入的效率要比多次插入效率更高
  - 事务中插入数据
  - 数据有序插入（主键）

#### 数据库结构优化

- 字段多的表进行分解：使用频率高的和频率低的进行拆分，因为使用频率低的存在会导致查询效率降低
- 对于经常连表查询的表，可以考虑建立中间表

#### 优化器优化

开启MRR：将ID或者键值读到buffer排序，通过将随机磁盘读转换为顺序磁盘读，减少磁盘IO，提高索引查询性能

磁盘预读：考虑到读写的局部性原理，将某一页数据请求时，预读后面几页的数据放到缓冲区

#### 结构优化

读写分离



### 大表的优化

当某个表的数据量很大的时候，如何优化？

- 限定数据的范围：将查询的数据限定在某个小范围内进行
- 读写分离：数据库的拆分方案，从库管理读，主库管理写
- 分库分表：进行垂直拆分和水平拆分

### 分库分表

数据量很大的时候，索引优化和主从机制带来的性能提升不明显了，此时需要考虑分库分表的策略

数据的切分一般分为两种方式：垂直切分和水平切分

#### 垂直切分

垂直划分数据库是根据业务进行 划分，如：商城数据库，可以将数据库中涉及到商品、订单、用户的表划分出一个库，通过降低单库的大小来提升性能，分表就是将一个大表中数据根据业务进行拆分成多个表。

优点：

- 行记录变小，数据页可以存放更多的记录，查询时减少IO次数

缺点:

- 主键出现冗余，需要管理冗余列
- 会出现联表查询
- 依然存在单表数据量过大问题

#### 水平切分

按照一定的规则，比如根据时间和ID的序列值进行数据划分，每个数据库的结构一致，但是数据库的数据量得以降低，从而提升性能

优点：

- 单库的数据量得以减少
- 性能提升，表结构不变，程序改动少

缺点：

- 分片的事务一致性难以解决
- 数据分片在扩容时需要转移