# 计算机操作系统

## 1 内核

![image-20210927131110690](https://gitee.com/Jia_bao_Li/img/raw/master/img/Linux%E5%86%85%E6%A0%B8.png)



#### 1.1 进程和线程

程序：计算机中许多的代码、函数、类、变量等等组成的集合。程序是进程的基础，程序的多次运行可以产生多个进程

进程：操作系统中运行的应用程序（程序就是一系列代码、函数、类的集合），进程其实代表了运行状态的一组程序，进程在不同的时间会有不同的状态，但是程序是保存下来的，是不会有变化的内容

![image-20210929234607769](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E8%BF%9B%E7%A8%8B%E7%A8%8B%E5%BA%8F%E7%9A%84%E7%B1%BB%E6%AF%94.png)

线程：CPU调度的最小执行单位，实质上进程由若干线程组成，线程共享进程的一部分内存空间，而各个线程也具有自己所私有的内存区域。

#### 1.2 地址空间和物理地址

内存区域通过指针寻址，因此内存管理的空间大小和CPU字长有关。32位电脑是2^32B长度，64位的是2^64B。

<font color='red'>地址空间的最大长度和实际内存数量无关，因此称为虚拟地址空间</font>

物理地址是值物理内存的具体位置。

#### 1.3 内核空间和用户空间

![image-20211025144902839](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E8%99%9A%E6%8B%9F%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4%E5%88%92%E5%88%86.png)

Linux将虚拟空间地址划分为了两部分：内核空间和用户空间

用户空间：系统中的每个用户都有自身的虚拟地址范围，0到TASK_SIZE，作为用户程序执行任务所使用的空间

内核空间：TASK_SIZE到最大长度处是内核空间，保留给内核专用，用户进程不能访问

内核态：用户进程想要执行任何内核提供的功能（影响系统的操作），需要借助系统调用向内核发起请求，内核审核检查请求，通过了就执行系统调用申请的操作，完成之后返回用户态。<font color='red'>执行系统调用进入的内核态可以访问用户空间，硬件中断的内核态不能访问用户空间</font>

用户态：在用户空间执行运行的进程所处的状态。用户态的进程无法访问内核空间，无法读取内核空间的数据，无法执行内核空间的代码，可以<font color='red'>防止用户操作不当导致系统的崩溃、防止进程无意之间修改彼此的数据造成干扰</font>

#### 1.4 页表

内核的虚拟地址空间和物理内存的映射通过一种特殊的数据结构来实现——页表。

多级页表对于虚拟地址空间中不需要的区域，不会创建中间页或页表，节省了大量的内存

Linux采用的是四级页表，一般采用的是三级页表。

![image-20210926215836953](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E5%A4%9A%E7%BA%A7%E9%A1%B5%E8%A1%A8.png)

PGD(page global directory)全局页目录：是一个数组，用来索引进程中的一个数组（每个进程中只有一个）

PMD（page middle directory）中间页目录

PTE（page table entry）页表数组：页表的索引，虚拟内存页和物理内存（页帧）映射完成

虚拟地址转换为物理地址的优化：

- MMU内存管理单元：优化内存访问操作
- 地址转换频繁出现的地址，缓存到特定的高速缓存中

#### 1.5 内存映射和内存分配

下图是进程中的内存排布情况，会通过这样的一个内存分布和实际物理内存进行映射

![image-20211025145105818](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E8%BF%9B%E7%A8%8B%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4%E7%9A%84%E6%8E%92%E5%B8%83.png)

##### 1.5.1 内存映射

**<font color='red'>内存映射</font>**：是一种抽象手段，将数据传输到进程的地址空间中，进程可以像访问物理内存一样访问虚拟地址内存，所作的修改会自动传输到原数据源。如：文件映射到内存中，处理只需要读写内存即可读写文件内容，内核会保证修改都会自动同步到文件中。

##### 1.5.2 内存分配

内存分配的时候需要实时记录内存的已分配和空闲区域，避免两个进程分配到同一块内存区域

#### 1.6 系统调用

是用户空间程序用来申请获取内核态的特权级别的API，调用系统调用就会向内核申请权限，内核审核之后就执行系统调用的功能并返回结果。

#### 1.7 设备管理和设备驱动

> 万物皆文件——Unix箴言

对于Unix下，可以将设备抽象为文件，通过操作文件就可以操作设备

设备驱动程序：可以通过操作设备对应文件从而实现和设备通信的代码集合（可以在设备上读取和写入数据的程序）

外设分为两大类：

- 字符设备：提供连续的数据流，应用程序可以顺序读取，一般不支持随机读取，此类设备支持按字节/字符读写数据
- 块设备：应用程序可以随机访问设备数据，程序可自行确定读取数据的位置，磁盘就是块设备。数据的读写通常以块（一般512B）的倍数读取

#### 1.8 网络

网卡也可以通过设备驱动程序控制，但因为网络协议的存在导致数据包存在协议头，必须针对协议的内容进行数据包的拆包/装包、分析然后才能将数据进行传递

对于这一功能的实现就是套接字：<font color='red'>应用程序、文件接口、内核的网络实现之间的代理</font>

#### 1.9 文件系统

不同的文件系统基于的概念抽象有较大差异，因此为了屏蔽底层文件系统的特性，需要有一个软件层，用来实现屏蔽底层细节的功能。

![image-20210926225158189](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E8%99%9A%E6%8B%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F.png)

#### 1.10 缓存

内核使用缓存来改进系统性能。

从低速的块设备读取的数据暂时保存在内存中，以便于下次读取该数据时绕过低速设备直接从内存中读取，提升了数据的交换速度。内核基于页的内存映射来实现访问设备，因此缓存一般也按照页组织，称为页缓存

#### 1.11 模块和热插拔

模块：可以在运行时向内核添加功能的组件，比如：设备驱动、文件系统、网络协议等，模块本质上就是普通的程序，只是运行在内核空间而不是用户空间。模块需要保证内部的代码块在初始化/终止，以便向内核注册和注销模块。

实际上，任何内核子系统都可以模块化，这就使得宏内核和微内核有些类似了。

热插拔：运行时内核动态的增加模块到内核空间执行。

#### 1.12 双向循环链表

内核中内存管理主要是采用双向的循环链表。对于表头表尾元素访问O(1)

## 2 进程管理和调度

内核的进程管理需要保证：

- 进程之间一般不允许相互干扰，除非有特殊要求
- 内核需要公平分配每一个进程的CPU执行时间
- 内核需保证CPU共享，确保CPU分配公平
- 内核在切换进程时需要保留进程的上下文，保证切换回来时可以直接从上一次切换的位置恢复执行

进程优先级：根据任务的紧要程度获取不同的进程优先级，优先级高的一般会先执行，同时也可能会获取更多的CPU执行时间。

抢占式任务分配：每个进程都分配一定的时间段执行，到该任务的允许时间段就会抢占CPU开始执行

**<font color='red'>中断</font>**：由外围设备的某些操作（磁盘传输数据完毕或者网络数据包到达）引起的，中断会暂停用户进程和内核进程，先响应中断操作才能恢复进程运行。<font color='red'>中断具有最高的优先级</font>

**<font color='red'>系统调用</font>**：当用户进程需要内核提供的某些功能时，会发起系统调用申请该功能，然后由内核执行该系统调用并返回结果

**<font color='red'>异常</font>**：程序运行时出现了某种问题而不能继续执行，CPU一般会直接kill出现异常的程序

### 2.1 进程概述

#### 2.1.1 进程的组成

- 程序的代码
- 程序处理的数据
- 程序所执行到的指令——指令寄存器保存记录
- 进程的堆栈（通用寄存器保存）
- 系统资源：打开的文件、网络端接收到的内容
- 进程控制信息：包含了进程当前的状态信息、堆栈信息、页表信息等等

#### 2.1.2 进程和程序的关系

程序：计算机中许多的代码、函数、类、变量等等组成的集合。程序是进程的基础，程序的多次运行可以产生多个进程

进程：操作系统中运行的应用程序（程序就是一系列代码、函数、类的集合），进程其实代表了运行状态的一组程序，进程在不同的时间会有不同的状态，但是程序是保存下来的，是不会有变化的内容

![image-20210929234607769](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E8%BF%9B%E7%A8%8B%E7%A8%8B%E5%BA%8F%E7%9A%84%E7%B1%BB%E6%AF%94.png)

#### 2.1.3 进程的特点

- 动态性：进程是具有状态的，在不同时间进程的状态并不一样，会更具数据的输入输出发生相应的变化
- 并发性：进程可以被独立调度占用处理机执行相应的任务。并发并行
- 独立性：不同进程之间不会相互影响，需要内存和CPU的协调合作
- 制约性：数据共享/进程同步会导致进程之间可能会相互制约

#### 2.1.4 进程控制块

进程控制块（PCB）：一个数据结构，操作系统用来管理控制进程运行所使用的信息集合

进程控制块描述进程的基本情况和运行变化的过程，<font color='red'>进程控制块是进程存在的唯一标志</font>

进程创建——为进程生成一个PCB

进程终止——回收进程的PCB

**PCB包含的内容**：

- 进程标识信息：唯一表示一个进程的信息
  - 进程的标识（PID）
  - 父进程标识
  - 用户标识
- 处理机状态信息保存区：保存程序的运行现场信息
  - 用户可见寄存器：用户程序使用的数据、地址寄存器等
  - 控制和状态寄存器：程序计数器PC、程序状态字PSW
  - 栈指针：过程调用/系统调用/中断处理需要用到的内容
- 进程控制信息：
  - 调度和状态信息，用于操作系统调度进程并占用处理器
  - 进程间通信信息：进程通信使用的各种标识、信号、信件等，存放在接收方的进程控制块
  - 存储管理信息：包含本进程内存映像的数据结构
  - 进程使用的资源信息：进程使用的文件等资源
  - 数据结构连接信息：进程可以连接到一个进程队列中，或连接到相关的其他进程的PCB

**PCB数据结构的实现：**

- 链表实现：同一状态的进程的PCB组成一个链表，多个状态对应不同的链表。比如：就绪链表、阻塞链表、等待链表等
- 索引表：同一个状态的PCB归入同一个index索引表（数组），多个状态对应多个索引表

相比索引表，链表的实现删除增加元素更方便。根据需求和特点选择合适的数据结构

#### 2.1.5 进程的状态

**进程创建**：系统初始化、用户请求创建进程或者运行进程执行系统调用创建进程

**进程运行**：当进程获取CPU开始执行操作的时候

**进程等待**：当没有分配到CPU资源、或者需要的数据没有到达，亦或是进程的某个操作无法完成（进程自身阻塞自己）

**进程唤醒**：其他进程或者操作系统唤醒

**进程终止**：进程任务完成或者错误退出或者操作系统/其他进程强制终止

**进程挂起**：进程没有占用内存空间，处在挂起状态的进程映像在磁盘上。实质上就是将进程从内存转移到外存上

- 阻塞挂起状态：进程在外存中等待某个事件发生
- 就绪挂起状态：进程在外存，只要进入了内存，即可运行

### 2.2 进程管理

创建进程的事件：

- 系统初始化
- 用户请求创建一个进程
- 运行的进程执行了创建进程的系统调用

- exec：加载程序取代当前运行的进程（会覆盖原来进程的堆栈信息）
- fork：复制当前进程作为子进程

写时复制技术（Copy On Write）：减少fork带来的复制开销。子进程只是先记录父进程的页表内容，等到子进程实际使用了父进程内存中的数据时，再去复制相应的数组到自身的内存中去，这样就减少了fork之后就复制父进程的数据所带来的开销

fork进程之后，一般最好将不再需要使用的文件或者套接字及时关闭，因为引用计数增加，如果要彻底放弃关闭该文件需要计数为0，如果有个进程不使用该文件但是也忘记了关闭该文件，那么这个文件很可能不会被关闭一直保留，直到引用它的进程全部关闭。

wait()系统调用：父进程用来等待子进程结束，避免僵尸进程的产生，就算父进程不关心子进程的状态，也最好使用wait相关的系统调用，可以避免僵尸进程的出现

- 子进程向父进程返回一个值，父进程接收这个值并进行处理

exit()结束进程并返回一个值

![image-20211002181617327](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81%E7%BC%93%E7%BC%93.png)

#### 僵尸进程的处理和避免

僵尸进程危害：僵尸进程会占用进程号，内核的进程号有限，如果进程号全被僵尸进程占用将不能再开启进程

僵尸进程的探查：Linux：`top`查看是否存在僵尸进程，然后使用`ps aux | grep -w 'Z'`查找

僵尸进程的清理：直接杀死父进程，父进程死亡之后，子进程变变为孤儿进程，托管给init进程，init进程会周期性的调用wait系统调用来清除僵尸孩子

僵尸进程的避免：init接管的进程都不会变成僵尸进程，init会定期wait清理

- 父进程使用wait监听子进程的状态，fork子进程后调用wait，当子进程结束，内核会通知一个信号给父进程，父进程可以使用处理该信号的函数清理子进程
- 生成子进程时使用两次fork函数，然后让第一个fork的子进程结束，然后第二个孙子进程称为孤儿进程，孤儿进程就会被托管给init，init来负责该进程的回收处理

### 2.3 线程管理

线程：进程当中的一条执行流程。可以并发执行，且线程之间共享相同的地址空间

#### 2.3.1 为什么使用线程？

多进程维护进程的开销较大，且进程之间通信比较麻烦

#### 2.3.2 线程的优缺点

优点：

- 一个进程可以存在多个线程
- 各个线程之间可以并发的执行
- 线程之间共享进程的地址空间和文件资源

缺点：

- 一个线程崩溃会导致所属进程的所有线程崩溃

#### 2.3.3 进程和线程的比较

- 进程是资源分配的单位，而线程是CPU调度单位
- 进程拥有一个完整的资源平台，而线程只拥有一部分独占资源（寄存器、栈）
- 线程同样具有创建、就绪和运行三种状态，转换关系也一样
- 线程相比进程的优点：
  - 线程创建、终止、切换所花费的时间比进程短
  - 同一进程内部的线程通信不需要通过内核进行，因为共享同一个进程的内存和文件资源，通信远比进程之间的通信要简单方便

#### 2.3.4 线程种类和实现

##### 2.3.4.1 用户线程

用户空间实现的线程机制，不依赖于操作系统的内核，由一组用户级的线程库函数完成线程的管理（创建、调度、同步和终止）

- 线程的维护由相应的进程来完成，不需要操作系统内核了解用户线程的存在，可用于不支持线程技术的操作系统
- 每个进程需要维护自己私有的线程控制块（TCB），记录跟踪内部线程的状态信息。TCB由线程库函数维护
- 用户级线程切换无需内核态的切换，切换速度很快，由线程库函数完成
- 进程可以定义自己的线程调度算法

用户级线程的缺点：

- 阻塞性的系统调用？一个线程系统调用阻塞，导致整个进程阻塞等待
- 一个线程执行之后，除非该线程主动交出CPU资源，不然进程中其他线程都没法执行
- 和进程相比，每个线程分配到的时间片较少，执行较慢

##### 2.3.4.2 内核线程

内核空间实现的一种线程机制，由操作系统来完成线程的管理（创建、执行、调度、同步和终止）

- 内核线程由内核维护进程和线程的上下文信息（PCB和TCB）
- 线程调度、切换和终止由系统调用/内核函数来进行，内核完成的，系统开销比较大
- 一个内核线程发起系统调用而阻塞，不会导致其他内核线程阻塞
- 时间片按照线程进行分配，多线程的进程分配的时间片更多

内核线程的缺点

- 开销大：

##### 2.3.4.3 轻量级进程

内核支持的用户线程，一个进程可有一个或多个轻量级进程，每个轻量级进程由一个单独的内核线程来支持



##### 2.3.4.4 内核线程和用户线程映射关系

- 一对一：一个用户线程对应一个内核线程
- 多对一：多个用户线程对应一个内核线程
- n对m：n个用户线程对应m个内核线程

#### 2.4 上下文切换

进程或者线程在切换的时候，需要将相应的一些必要信息保存起来放到PCB或TCB中，并选择另外一个进程或线程执行

上下文信息：

- 寄存器
- CPU状态信息

### 2.4:star: CPU调度

不可抢占式：调度程序必须等待事件结束，只能等程序执行完毕

**可抢占式**：调度程序在中断响应后执行，当前运行进程从运行切换到就绪或者从就绪切换为运行，当前运行的线程可以被换出

#### 2.4.1 调度原则

调度需要参考以下的一些指标来评价调度算法的好坏：

- CPU使用率：CPU处于忙状态所占时间的百分比
- 吞吐量：单位时间内完成的进程数量
- 周转时间：一个进程从初始化到结束，包括等待时间所花费的总时间
- 等待时间：进程在就绪队列中等待的总时间
- 响应时间：一个请求被提交到第一次响应所花费的总时间

下面两个因素很难完全都考虑：

- 低延迟：响应很快

- 高带宽：数据传送快

公平和非公平：

- 公平：保证每个进程占用相同的CPU时间，但是有的进程任务更重要更需要时间

#### 2.4.2 :star:**调度算法**

##### 2.4.2.1 FCFS（先来先服务）

队列实现的调度算法，在就绪队列里面，先进队的先执行

优点：

- 实现比较简单，使用简单的队列就可以

缺点：

- 平均等待时间波动较大
- 花费时间少的任务可能排在时间长的任务之后
- 可能导致I/O和CPU之间的重叠处理
- 没有考虑抢占式

##### 2.4.2.2 短作业优先

进程任务花费时间少的任务先执行，按照预测的完成时间来将任务入队

- 抢占式：后续任务时间短，执行这个任务，阻塞正在运行任务
- 非抢占式：如果后续新加入任务小于当前任务执行时间，不会抢占当前进程，加入就绪队列最前面

最优平均等待时间：平均等待时间最短的任务排列方案执行

缺点：

- 连续短任务导致长任务饥饿
- 需要知道一个进程的执行时间

##### 2.4.2.3 HRRN（最高响应比优先）优先级队列

根据任务的情况计算响应比（等待时间+执行时间）/执行时间，大的优先级高

- 不可抢占
- 关注了进程等待时间
- 防止了无限期推延

缺点：

- 还是需要知道进程执行时间

##### 2.4.2.4 Round Robin（轮询）

使用时间切片和抢占来轮流执行任务

- 公平策略
- 时间片选择很重要
  - 时间片长：等待时间过长，极限情况退化为FCFS
  - 时间片短：反应快，但是吞吐量受到很大影响

缺点：

- 可能会出现频繁的上下文切换，开销较大

想要让轮询方法的效率较好，需要选择一个合适的时间片大小。<font color='red'>经验：</font>维持上下文开销处于1%之内

就绪队列划分成独立的队列：

- 前台（交互）进程：使用轮询
- 后台：FCFS

固定优先级：

- 先处理前台，后处理后台
- 可能存在饥饿

时间片轮转：

- 每个队列确定一个CPU调度的总时间
- 前台80%，后台20%

##### 2.4.2.5 MLFQ多级反馈队列

优先级队列中进行轮询

- 根据任务的优先级动态调整CPU时间片
- 任务在当前时间片没有完成，降低优先级

优点：

- CPU密集型任务优先级下降快
- IO密集型停留在高优先级

##### 2.4.2.6 公平调度算法

用来控制用户对系统资源的访问

- 保证不重要的组无法垄断资源
- 没有达到资源使用率目标的组获取更高的优先级

### 2.5 :star:进程同步

**临界区**：指进程中的一段需要访问共享资源并且当另一个进程处于相应代码区域时便不会执行的代码区域

**互斥**：当一个进程处于临界区并访问共享资源时，没有其他进程会处于临界区并且访问任何相同的共享资源

**死锁**：两个或两个以上进程，相互等待完成特定任务，而导致最终任务没法执行完毕

**饥饿**：一个可执行的进程，一直被调度器忽略不能得到资源执行

![image-20211002221537987](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E8%BF%9B%E7%A8%8B%E5%90%8C%E6%AD%A5%E7%9A%84%E5%AE%9E%E7%8E%B0.png)

#### 2.5.1 禁用中断（只使用单处理器）

没有中断，就没有上下文切换，因此没有并发

- 硬件将中断处理延迟到中断被启动之后
- 有相关的硬件指令来实现中断的禁用

进入临界区：

- 禁用中断

离开临界区：

- 开启中断

缺点：

- 中断被禁用，线程无法被停止，整个系统都暂停
- 导致其他线程处于饥饿
- 无法限制响应中断的响应时间

#### 2.5.2 基于软件的解决（复杂）

需要硬件保证原子操作：

简单的实现代码：

```java
int turn = i;          // 表示轮到谁执行的变量，利用这个变量实现
do {
    while (turn!=i) ;  // 进入临界区前的判断，当没有轮到当前线程执行时，一直循环等待资源
    critival section;  // 临界区代码
    turn=j;            // 退出临界区的操作，释放资源，turn转向j进程
} while (1);

// 满足互斥，但是不满足progress前进
// 进程i执行完不再进入临界区时，进程j还需要进入，但是这个时候i不再进入，j就不再可以进入临界区执行
```

改进：

```java
int turn = i;          // 表示轮到谁执行的变量，利用这个变量实现
boolean flag[] = new boolean[2];   // 记录当前进程是否想要进入临界区
flag[j] = true;        // j进程想要进入临界区
do {
    while (flag[j]&&turn==i) ;  // 进入临界区前的判断，当没有轮到当前线程执行时，一直循环等待资源
    critival section;  // 临界区代码
    // 退出临界区操作
    falg[j]=false;
    turn=i;
} while (1);
```

#### 2.5.3 高级抽象——锁

- 获取锁——进入临界区之前

- 释放锁——退出临界区

硬件级的原子操作：

- test-and-set：CAS操作，比较并交换，满足值为这个并进行设置
- exchange：交换两个值，也是一个原子操作


```c
// 忙等方式
class Lock {
    int value = 0;
}
Lock::Acquire() {
    while (test-and-set(value));  // 忙等，忙等比较消耗CPU资源，也成为自选操作
}

Lock::Release() {
    value==0
}
// 这种实现适合任务时间短，等待的时间不长的情况，自选的操作比进程切换消耗小，更合适
```

```c
// 无忙等待
class Lock {
    int value=0;
    WaitQueue q;
}
Lock::Acquire() {
    while (test-and-set(value)) {  // 判断是否可以进入临界区，不可以进入就加入到等待队列等待资源
        // 将当前进程加入等待队列;
        schedule();
    }
}
Lock::Release() {
    value=0;
    // 从等待队列选择一个任务t执行；
    wakeUp(t);  // 唤醒进程
}

// 这种实现更适合那些执行任务时间比较长的情况，减少了自选带来的CPU消耗
```

借助了计算机硬件底层的原子指令来实现的

```c
int lock=0;
int key;      // 定于进程内的变量，表示当前进程是否想要执行
do {
    key=1;           // 表示当前进程想要执行
    while (key==1) exchange(lock,value);  // 尝试交换两个变量的值，只有lock为0时才可成功退出循环
    // 临界区
    lock=0;  // 退出临界区
}
```

优点：

- 简单
- 适用于多处理器
- 可用于支持多临界区

缺点：

- 忙等消耗处理器资源
- 进程离开临界区多个进程等待，容易出现饥饿
- 死锁现象：低优先级获取锁，但是高优先级进入抢占锁，低优先级进程没法释放锁，导致死锁

#### 2.5.4 :star:死锁

每个进程拥有一个资源并请求其他资源，死锁可能发生

```java
import java.lang.InterruptedException;

/**
* jps:查看正在运行的Java进程的pid
* jstack pid:查看进程的堆栈信息
* 死锁可以在堆栈信息看到
*/
public class DeadLock {
    public static void main(String[] args) {
        Object o1 = new Object();
        Object o2 = new Object();

        new Thread(() -> {
            synchronized(o1) {
                System.out.println("线程A获取资源o1并锁住");
                try{
                    Thread.sleep(1000);
                }catch (InterruptedException e) {
                    e.printStackTrace();
                }
                synchronized(o2) {   // 尝试获取资源o2
                    System.out.println("线程A获取资源o2并锁住");
                    try{
                        Thread.sleep(1000);
                    }catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                }
            }
        },"tA").start();
        new Thread(() -> {
            synchronized(o2) {
                System.out.println("线程B获取资源o2并锁住");
                try{
                    Thread.sleep(1000);
                }catch (InterruptedException e) {
                    e.printStackTrace();
                }
                synchronized(o1) {     // 尝试获取资源o1
                    System.out.println("线程B获取资源o1并锁住");
                    try{
                        Thread.sleep(1000);
                    }catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                }
            }
        },"tB").start();
    }
}
/**
* 死锁处理
* 	1. 避免访问一个资源请求另外一个资源    									  预防措施
*	2. 使用锁的时候尽量使用tryAcquire，就算获取不到锁也不会一直等待资源导致阻塞     避免措施
*/
```



##### 2.5.4.1 模型分析

建立进程和资源分配有向图：观察图中是否存在循环

​       ![image-20211003164247307](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E5%AD%98%E5%9C%A8%E6%AD%BB%E9%94%81%E7%9A%84%E8%B5%84%E6%BA%90%E5%88%86%E9%85%8D%E5%9B%BE.png)       |          ![image-20211003164330619](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E4%B8%8D%E4%BA%A7%E7%94%9F%E6%AD%BB%E9%94%81%E7%9A%84%E8%B5%84%E6%BA%90%E5%88%86%E9%85%8D%E5%9B%BE.png)

               存在死锁                                      不存在死锁
- 不存在环——>没有死锁
- 存在环
  - 每个资源类只有一个实例，死锁
  - 每个资源类有几个实例，可能死锁

##### 2.5.4.2 死锁特征

四个条件都满足**可能**出现死锁：

- <font color='red'>互斥</font>：一个时间只有一个进程使用资源
- <font color='red'>持有并等待</font>：进程有一个资源并等待另外进程持有的资源
- <font color='red'>非抢占式</font>：资源只能进程资源放弃，其他进程不能抢占，只能等待进程执行完毕
- <font color='red'>循环等待</font>：A等待B，B等待C，C又等待A，这一类的循环等待问题

##### 2.5.4.3 死锁处理

- <font color='red'>死锁预防</font>：打破死锁出现的某个条件即可。最好的方法就只有处理循环等待。其他几种条件打破带来的消耗较大
- <font color='red'>死锁避免</font>：动态监测资源分配状态，确保不会有环形等待的情况。（银行家算法）
- <font color='red'>死锁检测</font>：查找死锁的开销比较大，很多系统有时候会忽略死锁，假装没有出现死锁。定期执行检测算法，查找是否存在死锁
- <font color='red'>死锁恢复</font>：杀掉其中一个进程/或者一定时间内清除一个进程知道死锁消除
  - 进程优先级
  - 进程运行了多久以及需要多常时间结束
  - 进程占用资源
  - 进程完成需要的资源

### 2.6 :star:信号量和管程

![image-20211002230544922](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E5%BA%95%E5%B1%82%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6.png)

#### 2.6.1 信号量

信号量用来解决允许多个进程进入临界区的情况，比如读操作的情景可以多个进程同时读。

抽象数据类型：

class Semphomore {
    int state;
    p() {
        state-1;  // 需要原子操作保证，如果sem<0,等待，否则可以继续，会阻塞
    }
    v() {
        state+1;  // 需要原子操作保证，如果sem<=0，唤醒等待的进程
    }
}
// 类似多轨铁路，当一个火车进入其中一条铁轨，铁轨数量减一，走出一个铁轨，数量加一
// 无可用铁轨，火车等待

信号量可以用来进行消费者生产者之间的同步：

- fullBuffer信号量：
- emptyBudffer信号量：
- 互斥信号量

```java
// 生产者消费者实现
class BounderBudder {
    mutex = new Semaphore(1);        // 互斥信号量
    fullBuffers = new Semaphore(0);  // 缓冲满的信号量
    emptyBuffers = new Semphore(n);  // 缓冲空的信号量
    
    void deposit(c) {
        emptyBuffer.p();
        mutex.p();
		// 将任务添加到缓冲区中
        mutex.v();
        fullBuffer.v();
    }
    
    void remove(){
        fullBuffer.p();
        mutex.p();
        // 从缓存区移出一个任务
        mutex.v();
        emptyBuffer.v();
    }
    
}
```

缺点：

- 存在死锁
- 需要精通信号量才不容易出错

#### 2.6.2 管程

目的：分离互斥和条件同步的关注

- **一个锁**：指定临界区，管程管理的线程只能有一个线程进入临界区
- **0或多个条件变量**，通知/等待信号量用于管理并发访问共享数据

Lock：

- acquire：获取锁
- release：释放锁

Condition：

- 允许等待（睡眠）的线程进入临界区
- 允许某个条件满足时，释放锁睡眠线程

- wait：释放锁，睡眠，重新获取锁之后返回
- signal：唤醒等待着，等待队列选择一个

管程实现生产者消费者：

```java
// 生产者消费者的管程实现
class BoundedBuffer {
    Lock lock;
    int count=0;
    Condition notFull,notEmpty;
    
    void deposit(c) {
        lock.acquire();
        while (count==n) {
            notFull.wait();  // 任务满就等待
        }
        // 添加任务到队列
        count++; 
        notEmpty.signal();   // 通知消费者消费
        lock.release();     // 释放锁
    }
    
    void remove() {
        lock.acquire();
        while (count==0) {
            notEmpty.wait(); // 为空就等待
        }
        // 移出任务
        count--;
        notFull.signal();  // 通知生产者生产任务
        lock.release();  // 释放锁
    }
}
```

### 2.7 :star:进程通信

#### 2.7.1 为什么要进行进程通信？

- <font color='red'>数据传输</font>：一个进程的数据需要发送到另外一个进程
- <font color='red'>资源共享</font>：进程之间共享相同的资源
- <font color='red'>通知事件</font>：进程之间发送消息，通知某种事件的发生
- <font color='red'>进程控制</font>：有些进程需要控制另外进程的执行，了解进程的状态

#### 2.7.2 进程通信的原理

<font color='red'>不同进程之间所使用的用户空间地址都是不同的，任何进程的全局变量在另外一个进程中是查看不到的。</font>因此进程之间想要交换数据、进程通信，就需要在内核中开辟一个缓冲区，用来把数据从用户空间拷贝到内核空间，然后内核调度传递给进程。

内核对进程数据的缓冲和传递就是内核的进程通信机制

![image-20210919110140652](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E8%BF%9B%E7%A8%8B%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86%E3%80%81.png)

#### 2.7.3 进程通信方式

- 直接
- 间接

- 阻塞
- 非阻塞

##### 2.7.3.1 管道

利用pipe函数创建一个管道，这个管道就是在内核中开辟一块缓冲区用来通信。管道由读端和写端组成。

实质上管道的读写就是内核缓冲区的读写。管道存在于内存中的文件

```shell
ls | more   # 管道命令，用来进程间通信，ls的输出作为more的输入
# ls（管道的写端） 和 more（管道的读端）都是shell的子进程
```

通信对象：

- <font color='red'>具有亲缘关系的父子进程</font>
- <font color='red'>具有亲缘关系的兄弟进程</font>

管道的缺点：

- 管道通信是单向的
- 缓冲区大小受限制
- 只能具有亲缘关系的进程之间通信
- 管道传送的是无格式字节流，管道读写双方需要事先约定数据格式（如多少字节算作一个消息）

##### 2.7.3.2 命名管道FIFO

<font color='red'>为了克服匿名管道只能用于亲缘关系之间的进程通信而提出的一种管道。</font>

命名管道严格遵循先进先出FIFO。

命名管道以**磁盘文件**形式存储，可以实现本机**任意两个进程通信**。

##### 2.7.3.3 消息队列（间接通信）

操作：

- 创建一个新的消息队列
- 通过消息队列发送和接收消息
- 销毁消息队列
- send(A,message)：发送消息到队列A
- receive(A,message)：从A接收消息

队列消息存储方式：

- 0容量：发送方等待接收方接收（同步的方式）
- 有限容量：在队列为空，接收方等待，队列满，发送方等待，其他情况接收方和发送方都可以继续工作
- 无限容量：发送方不需要等待

消息队列是消息的链表，具有特定格式，存放在内存中并由消息队列标识符标识，管道和消息队列的通信数据都是先进先出的原则。

消息队列存放在内核中，只有内核重启或者删除消息队列时，该消息队列才会消失。

消息队列可以实现消息的随机查询，消息不一定要以先进先出的次序读取，也可按照消息的类型读取，比FIFO更具优势。

<font color='red'>消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限制的缺陷</font>

##### 2.7.3.4 信号量

信号量是一个计数器，用于多进程对共享数据的访问，<font color='red'>信号量的意图在于进程间同步</font>，这种通信方式主要是用来解决同步相关的问题并避免竟态条件。

##### 2.7.3.5 信号

用于通知接收进程某个事件已经发生

- 信号可以在任意时刻发送给任意一个进程，无需知道该进程状态
- 不能传输需要交换的数据

<font color='red'>信号是软件层级对中断机制的一种模拟</font>，是一种异步通信机制，<font color='red'>信号可以在用户空间进程和内核之间直接交互</font>。内核可以通过信号来通知用户空间进程发生了哪些系统事件，信号主要有两个来源：

- 硬件来源：IO设备的异常或者用户键盘输入ctrl+c
- 软件中止：中止进程信号、其他进程调用kill函数、软件异常产生的信号等

##### 2.7.3.6 共享内存（直接通信）

多个进程可以访问同一块内存空间，可以及时看到进程对共享内存数据的更新

实现：

- 将共享的物理内存映射到进程逻辑地址当中

特点：

- 最快速
- 一个进程写另外一个进程立即可见
- 没有系统调用干预
- 没有数据复制
- 需要实现同步（程序员提供）

这种方式需要用到某些**同步机制**，比如互斥锁、信号量。

<font color='red'>最快最有用的进程通信方式</font>

##### 2.7.3.7 Socket套接字

此方法主要用于<font color='red'>客户端和服务端进程之间进行通信，支持TCP\IP网络通信</font>。

使用套接字来完成两端主机之间的通信过程

## 3 :star:内存管理

计算机的内存是一个分层次的体系结构，一个金字塔型的，越上面内存越小，读写数据速度更快

![image-20210928165151266](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%86%85%E5%AD%98%E5%88%86%E5%B1%82%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84.png)

内存碎片：

- 内碎片：分配出去的内存内部存在未被使用的内存，这部分内存被称为内碎片
- 外碎片：分配出去的多个内存中间夹杂很小的内存，这部分内存由于过小，很难被分配

### 3.1 连续内存分配

查找内存是否存在程序分配所需的内存大小。

连续内存分配的方式：

- 最先分配：找到最先出现的满足程序内存大小的内存块
- 最优分配：分配和程序所需内存大小最相近的内存块
- 最差分配：分配最大的一块内存给程序

这三种分配方式都会出现内存碎片的问题，内存碎片分为**内碎片**和**外碎片**

这种分配方式会将内存看成一个双向的循环链表，通过从头开始查找是否有满足程序所需大小的内存块来分配。

对于连续的内存块，会进行合并操作。

为了解决内存碎片的问题：

- 移动技术：尽量保证空闲分区是一整块的区域，避免产生内存碎片
- 针对内存不够的时候可以适用硬盘作为虚拟内存来解决内存不够的问题

### 3.2 非连续内存分配

**为什么使用非连续内存分配**：

连续内存分配会带来较多的内存碎片，导致内存利用不充分，有些浪费内存。

- 程序的逻辑地址是非连续的
- 更充分的内存利用和管理
- 非连续内存分配允许共享代码和数据
- 支持动态加载和动态链接

**非连续内存分配的缺点**：

- 内存管理所带来的开销较大
- 需要软硬件的协同配合降低开销

#### 3.2.1 分段

程序的分段（将不同部分分配到物理内存）：

- 主程序
- 程序数据
- 程序堆栈

分段技术需要做的事：

- 将不同的程序段映射到内存中
- 需要设置分段寻址方案

![image-20210928201113824](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E5%88%86%E6%AE%B5%E8%AE%BF%E9%97%AE%E5%AF%BB%E5%9D%80%E6%9C%BA%E5%88%B6.png)

![image-20210928201202807](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E5%88%86%E6%AE%B5%E7%A1%AC%E4%BB%B6%E7%9A%84%E5%AE%9E%E7%8E%B0.png)

#### 3.2.2 分页

将主存分成多个大小相等的页架。每个页架代表一块内存地址

逻辑地址也按照大小相同的页来划分，不同的页可放在不同的页架

程序在分配页架的时候不需要选择连续的页架。

有专门的数据结构来保证进程的内存完整性——页表

**分页划分机制：**

逻辑地址：页号+单元号

物理内存地址：页架号+单元号

单元号用来记录内存的在该页架的具体位置

**分页方式的地址转换——通过查询页表来获取对应的内存地址**

**内存分页的好处**：

- 内存分配的时候不再需要连续的地址空间分配，可以减少内存碎片
- 分页方便了内存中的数据和程序共享（页的共享比较方便）

#### 3.2.3 页表和快表（TLB）

**页表**是操作系统实现的用来管理逻辑地址和内存地址的映射的一种数据结构，本质上页表是一个键值对的数据结构，键对应的是逻辑地址的页，值对应的是逻辑地址对应的物理内存地址的页。

设置了页表之后，管理物理地址就可根据物理内存的页架号是否空闲来判断内存是否可用，记录有多少页空闲

![image-20210928195228208](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E9%A1%B5%E8%A1%A8%E7%9A%84%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2.png)

页表是放在内存中，因此，每次进行地址转换的时候都需要访问内存两次，这就降低内存的分配读取存储的速度，导致效率降低。为了改善这一状况，会将页表的部分内容（那些经常被访问的页表项）存储在缓存当中，访问缓存的效率相比访问内存，效率值更高。和没有增加快表的转换相比，只是将直接访问页表转换为了先访问快表，没有再去访问页表。（利用了缓存速度更快来提高效率）

**增加了快表缓存之后的地址转换流程**：

1. 根据逻辑地址中的页号查询页架号（先在缓存中查询）
2. 如果缓存中有，直接返回页架号，然后根据页架号和单元号找到物理内存地址
3. 如果缓存中没有，则需要访问内存中的快表，将页号对应的单元号查找并写入缓存中
4. 如果快表已满，则需要根据相应的缓存淘汰策略来删除旧表项

![image-20210928200045087](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E5%BF%AB%E8%A1%A8%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2.png)

#### 3.2.4 二级页表和多级页表

![image-20210928201848454](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E4%BA%8C%E7%BA%A7%E9%A1%B5%E8%A1%A8.png)

**<font color='red'>为什么采用多级页表?</font>**

- 减少页表所占用的内存
- 将程序中没有映射的页表项不需要再放入到页表，节省了不少的空间，但是增加了一定的开销

![image-20210928202244902](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E5%A4%9A%E7%BA%A7%E9%A1%B5%E8%A1%A82.png)

#### 3.2.5 反向页表（Inverted Page Table）

为什么需要反向页表？

- 正常的页表项64位寻址空间需要2^52个页表项，所占空间太大
- 反向页表只对实际物理内存制作表项，所需要的映射表项远远少于页表中表项，可以节省空间

从物理地址索引找到逻辑地址（程序代码或者数据的位置）

![image-20210928210106517](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E5%8F%8D%E5%90%91%E9%A1%B5%E8%A1%A8.png)

**反向页表的优点：**

- 转换表的所占空间减小了
- 转换表的大小和逻辑地址空间无关，只与物理地址空间有关

![image-20210928210340887](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E9%A1%B5%E5%AF%84%E5%AD%98%E5%99%A8%E7%9A%84%E4%BC%98%E7%82%B9.png)

**反向页表的缺点：**

- 可以根据页帧找到页号，但是不能根据页号找到页帧
- 在反向表中根据页号查找页帧不方便

**关联内存来解决**：

- 关联内存设计的内存还不能做到很大，且关联内存所需代价昂贵

**哈希查找方案来解决**：

反向页表中利用哈希函数来高效的查找页号对应的页帧号。

反向页表也是需要存储在内存中，因此为了减少内存访问开销，也是需要设置快表缓存来加速访问寻址

同时哈希函数由于哈希冲突的存在，需要想办法解决哈希冲突才能保证高效寻址不出现错误。

![image-20210928210701449](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E5%93%88%E5%B8%8C%E5%87%BD%E6%95%B0%E5%8F%8D%E5%90%91%E9%A1%B5%E8%A1%A8.png)

#### 3.2.6 段页式内存分配

将程序段的内存分配采用页表方式来分配内存，整个程序先按照段来进行分段，分段之后的每一个段再按照页式内存分配方案分配。

![image-20210928223527456](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E6%AE%B5%E9%A1%B5%E5%BC%8F%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D.png)

### 3.3 :star:虚拟内存

为了解决内存不够的问题，出现了一些技术：

- 手动的覆盖技术：只把需要的指令和数据放在内存中
- 自动的交换技术：将暂时不能执行的程序交换到外部存储中
- 自动的虚拟存储技术：以更小的页粒度为单位装入较大的程序，不把整个程序交换到外部存储，而是只将一部分的程序数据或者代码移出内存

#### 3.3.1 覆盖技术

将程序按照自身的逻辑结构，划分为若干个功能上相对独立的程序模块，那些不会同时执行的模块共享一块内存区域，按照时间的先来后到执行：

- 程序的必要部分：常驻内存
- 不常用的部分：平时放在外存中，使用时才装入内存

![image-20210928213617653](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E8%A6%86%E7%9B%96%E6%8A%80%E6%9C%AF.png)

#### 3.3.2 交换技术

操作系统进行的一项操作，将暂时不能执行的程序移出到外存中（将整个的程序移出），当程序需要执行时，就从外存中将程序重新读入内存。

- 相比覆盖技术，简化了程序员对于内存不够时的操作，减轻了程序员负担，但是增加了CPU的开销

- 缺点就是需要频繁的从外存中导入导出程序，开销比较大，因为外存的速度较慢

- 交换只在内存不够时才需要使用这一功能进行程序交换

- 交换区的内存大小需要确保可以满足程序交换，因此一般交换区大小设置为内存的大小

- 程序换入时内存位置的选择：最好采用动态地址映射，防止和其他程序出现内存位置冲突

![image-20210928214811156](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E4%BA%A4%E6%8D%A2%E6%8A%80%E6%9C%AF.png)

#### 3.3.3 虚存技术

#### 3.3.1 局部性原理

局部性原理是指：<font color='red'>程序在执行过程中的一个较短时期，所执行的指令地址和指令的操作数地址，分别局限于一定的区域</font>

- <font color='red'>时间局部性</font>：一条指令的一次执行和下次执行，一个数据的一次访问和下次访问都集中在一个较短的时间内
- <font color='red'>空间局部性</font>：当前指令和邻近的几条指令，当前访问的数据和邻近的几个数据都集中在一个较小区域内

为了更好的利用虚拟内存技术带来的优势，程序的设计要满足一定的局部性原理，才可以更好的实现高效的内存管理。

#### 3.3.2 虚存的基本原理

- 在装入程序的时候，不必要将整个程序装入内存，<font color='red'>只需要将当前需要执行的数据和代码（页面或者段）装入内存，程序就可以开始执行</font>
- 程序执行过程中，如果发现<font color='red'>需要执行的代码或者数据不在内存中（缺页或者缺段异常），处理器会通知操作系统将相应的页面或段调入内存，然后程序继续执行</font>
- 操作系统将<font color='red'>暂时不需要执行的页面或段调出保存在外存中，从而节省更多的空闲空间来装载需要执行的页面或段</font>
- <font color='red'>当外存中的代码或数据需要执行的时候，再从外存中调入内存中</font>

虚存=内存+保存程序数据的外存

**虚存的优点**：

- 空间更大：因为使用了硬盘作为一部分虚拟内存来使用
- 交换粒度更小：和硬盘虚拟内存交换的只是一小部分的程序代码或数据，交换的内存更小，因此效率相对交换技术更好
- 不连续性：物理内存的分配不连续

#### 3.3.3 虚拟页式内存管理

![image-20210928230150932](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E9%A1%B5%E5%BC%8F%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86.png)

![image-20210928230535257](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E8%99%9A%E6%8B%9F%E9%A1%B5%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E4%B9%8B%E9%A1%B5%E8%A1%A8.png)

![image-20210928231130652](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E9%A1%B5%E5%BC%8F%E8%99%9A%E6%8B%9F%E5%AD%98%E5%82%A8%E4%B9%8B%E7%BC%BA%E9%A1%B5%E4%B8%AD%E6%96%AD.png)

![image-20210928232148323](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E8%99%9A%E5%AD%98%E7%9A%84%E5%90%8E%E5%A4%87%E5%AD%98%E5%82%A8.png)

### 3.4 :star:局部页面置换算法

缓存淘汰算法和内存置换算法有一部分相同的算法应用

当内存或缓存已满，但是此时又需要加入新的内存页或者缓存项时

**算法实现的目标**：

- 尽可能减少后续出现缺页异常中断或者缓存已满需要更新的情况（减少硬盘的换入换出操作提高效率）
- 将那些经常被访问的需要常驻内存的页面或者热点缓存锁定，保证不会被删除置换或者过期

#### 3.4.1 最优页面置换算法

**思路**：

- 当缺页中断发生时，对于保存在内存当中的每一个页面，计算这些**页面在下一次访问之前**，还需要等待多长时间，从中选择等待时间最长的页面作为置换页面

**目的**：

- 确保在这一次缺页中断之后，再次发生缺页中断的概率尽可能的降低，从而减少硬盘的换入换出，提升计算机的程序执行效率和CPU的处理效率

**缺点**：

- <font color='red'>这个算法是一个理想情况，实际上，很难知道系统中的每个页面需要多久才会被再次访问</font>

**优点**：

- 可以<font color='red'>采用这个算法的逻辑去评价其他的页面置换算法的性能</font>
- 在一个模拟器上执行某个程序，记录每一次页面的访问情况，第二次运行的时候就可以使用最优算法

#### 3.4.2 先进先出算法FIFO

**思路**：

- 选择在内存中驻留了最长时间的页面并淘汰一个。

**实现**：

- 一般采用一个链表记录内存中的页面，位于链表顶端的是最早进入内存的页面，尾端是最晚进入内存的页面

**缺点**：

- 删除的页面可能是下一次需要使用的页面或者那些经常被访问的页面，并存在Belady现象（程序分配的物理页面越多，采用FIFO算法的缺页异常次数变多的一种现象），很少单独使用这一类算法

**优点**：

- 实现较为简单，使用一个链表即可实现

#### 3.4.3 最近最久未使用算法LRU

**思路**：

- 替换页面选择最久未被使用的页面（很长时间都没被读取或者加载的内存）并淘汰
- 类似于最优页面置换算法，但是这个实现依据与前期的访问特征来进行判断，最优算法是根据位来的访问情况进行判断

**缺点**：

- 开销比较大，需要记录页面的访问顺序，查找最久未被使用的开销比较大，此外每次判断当前元素是不是存在，存在需要更新该元素的位置

**优点**：

- 实现相对简单，实现使用哈希表和链表可以简单实现这一类算法

**算法实现**：

- 链表实现：维护一个链表来记录页面的访问顺序，链表首节点代表最近使用的页面，尾结点代表最久未被使用的节点
- 栈实现：访问某一页面的时候，判断堆栈是否存在，存在就将该元素出栈之后再重新入栈，没有直接入栈。每一次删除页面选择栈底的页面删除该元素（最就未被使用）

#### 3.4.4 时钟页面置换算法

**思路**：

- 借助页表项中的访问位，当一个页面被装入内存时，将访问位初始化为0，如果这个页面被访问，就将访问位置为1

**实现**：

- 整个页面组织为一个环形链表，将指针指向最老的页面（最先进来）
- 发生缺页中断时，首先判断指针处页面访问位是否为0，如果为0，立即淘汰，不为0，将其置为0，指针往下走，直到找到被淘汰的页面，然后将指针移动到淘汰页面的下一格

**缺点**：

- 相对开销还是比较大，还是需要找到最新访问过的页表项并将访问位置为1（硬件完成）。有的时候甚至需要空转一次，效率还是不高，比LRU效率低

**优点**：

- 使用了LRU的实现逻辑并结合了FIFO，改进了FIFO

#### 3.4.5 二次机会法（增强时钟算法）

**脏页**：页面被访问且执行了写操作

读页和写页的区别：脏页需要重新写回因公安，而读页因为数据并没有发生修改，可以不再写回硬盘，可以直接丢弃，着就减少了一次硬盘的写入，进一步提升效率

**思路**：

- 借用了页表项中的脏位和访问位，对于脏页（因为脏页数据需要将数据重新写回硬盘），总是在一次时钟头扫描中保留下来，因为多了脏位，所以页面有两次机会会被保留在内存中，对于读页，只有一次机会

**实现**：

- 和时钟置换算法一样，采用循环链表，只是采用了两个标志位来进行判断。对于访问位位1，就将其置为0，进入下一指针，如果访问位为0写位为1，将写位置为0，进入下一个，当两个位都为0，选择这个页面进行置换

**缺点**：

- 代价还是较高，不过比LRU，由于借助了硬件实现（页表的访问位和写位位于页表表项中），效率也还不错

**优点**：

- 改进了时钟算法，增加了脏页保留在内存的机会（两次）减少了硬盘的读写次数，相比时钟算法提高了效率

#### 3.4.6 最不常用法LFU

**思路**：

- 选择内存中页面被访问次数最少的页面替换淘汰

**实现：**

- 对每个页面增加一个访问计数器，发生缺页中断时，选择淘汰计数值最小的页面（更优实现：是否可以考虑结合时钟置换算法）

**缺点：**

- 虽然认为最不常使用后续也会不常被使用，但是实际情况不一定是这样。还是不能很好的接近最优置换算法

**优点：**

- 相比其他的置换算法实现，效率和硬盘的读写次数是最高的

**另外的实现**：

- 是否可以结合LRU和LFU，不仅考虑频率同时还考虑时间，每隔一段时间没被访问，次数就减小

#### 3.4.7 Belady现象

采用FIFO算法时，发现，程序的物理页面分配数量增加，发生缺页异常次数也增加

**出现这种现象的原因**？

- FIFO置换特征和进程访问内存的动态特征相矛盾，置换出去的页面不一定是后续程序不需要使用的页面，因此与置换算法的目标（置换最少使用的页面）不一致

#### 3.4.8 局部页面置换算法的问题

假定了局部页面置换算法的进程分配页帧固定

但是实际上，进程所需要的页帧在不同时期不一样，是一个动态变化的过程 

### 3.5 全局页面置换算法

工作集：一个进程**当前**正在使用的**页面集合**

可以展示一个进程在不同时间段的内存访问特点

常驻集：当前时刻，进程实际驻留在内存当中的页面集合

##### 3.5.1 工作集置换算法

当页面不在工作集窗口之中时就会开始移出这些页面。

- 实现类似于**滑动窗口算法**

##### 3.5.2 常驻集置换（缺页率页面置换算法）

![image-20210929231027724](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E7%BC%BA%E9%A1%B5%E7%8E%87%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95.png)

缺页率：缺页次数/内存访问次数

影响因素：

- 页面置换算法
- 分配给进程的页面数量
- 页面的大小
- 程序本省的编写



实现：

- 缺页率高的时候，适当增加工作集窗口大小
- 缺页率低，适当减小工作集窗口
- 实现动态的调整内存中的工作集 

实际的算法：

- 将缺页率转换为上次缺页到这次缺页之间的时间
- 时间大，说明缺页率低，减小工作集
- 时间小，说明缺页率低，增大工作集
- 设置一个时间阈值，根据这个阈值判断大小

##### 3.5.3 抖动问题

当程序可用分配页面变少，导致进程的工作集不能被包含在内，频繁的缺页中断异常处理，CPU的利用率降低，计算机的工作性能变得很差

出现抖动的原因：

- 常驻内存的程序越来越多，分配给进程的物理页面数变少，缺页率提升
- OS需要选择合适的进程数量和进程需要的内存页帧，以保证高并发下的CPU效率和缺页率之间达到一个较好的平衡

高并发下的性能优化其实就是这种类似的思路，当你高并发下计算机的性能出现瓶颈的时候，需要找到出现这个瓶颈的主要原因，根据这个原因去优化相关的内容或者改进某些算法。

主要的性能瓶颈有内存、还有就是频繁的IO导致CPU等待，不能很好的利用CPU、最后就是CPU的本身性能问题

## 4 IO管理/设备管理

I/O设备，用来给计算机系统和外界进行信息交换和存储的一种介质（不同计算机之间通过网卡，电子设备通过链路）IO的效率和实现方式很大程度影响了计算机系统的处理能力

### 4.1 IO设备分类

按照传输方向分类：

- 输入设备：键盘、鼠标、扫描仪等
- 输出设备：屏幕显示器、打印机等
- 输入输出设备：磁盘、网卡等

按照管理方式分类：

- 字符设备：以字符为单位进行信息交换，鼠标、显示器等
- 块设备：以固定大小的数据块进行信息交换，比如磁盘
- 网络设备：用于不同设备之间通信的设备，如网卡。网络设备可以抽象为字符设备或者块设备进行管理

### 4.2 设备管理的目的

- 克服设备和CPU速度不匹配的问题，使得主机和设备充分的并行工作，提高设备的使用效率
  - 不同的设备数据传输速率不一致：可能会相差多个数量级
- 对设备进行**抽象**，屏蔽设备的物理细节和操作过程，配置驱动程序提供统一界面或者接口，提供给用户或者高层软件来使用
  - 抽象为文件系统的节点，通过文件操作进行设备管理
  - 裸设备：不被操作系统直接管理，应用程序读写，IO效率更高

### 4.3 设备管理的功能

- 设备中断处理
- 缓冲区的管理
- 设备的分配和去配
- 设备驱动调度
- 实现虚拟设备（鼠标虚拟为操作杆）

### 4.4 设备管理的层次

- IO硬件：
  - I/O设备及其接口线路
  - 控制部件
  - 通道
- I/O软件：
  - 系统级I/O软件
  - 用户空间I/O软件

### 4.5 :star:IO控制管理方式

设备控制器：IO设备中的机器不见和电子部件分开处理，其中的电子部件就是设备控制器，负责和操作系统之间的狡猾逻辑，设备控制器还有许多其他的别名（设备适配器，IO控制器，IO接口）

设备控制器需要实现的功能：

- 接收和识别**CPU或者通道**发送来的命令
- 实现**数据交换**
- 发现和**记录设备以及自身的状态信息**，供CPU处理使用
- 多台设备的**地址识别**

**IO控制的几种方式**

- 轮询方式：
  1. 当遇见IO处理操作时，CPU需要等待设备就绪
  2. 设备未就绪，CPU需要不断轮询设备状态（会中断原程序的执行）
  3. 当设备就绪后，再进行数据的传输处理。（阻塞式的处理方式，CPU和设备串行，效率低下，处理IO需要暂停程序的执行）
- 中断方式：
  1. 当遇见IO处理操作时，CPU不需要等待设备就绪，只需要向IO控制器发送IO指令
  2. CPU可以继续执行其他的任务或者指令。
  3. 等到设备就绪后，通知CPU执行中断处理器程序，进行数据的传输处理。
  4. CPU不等待设备，但是需要参与数据处理和传送过程。（如果CPU实现了异步IO，可以继续执行当前进程的指令，如果没有，可以挂起当前进程执行其他程序，还是可能中断源程序的执行）
- DMA（直接存储器访问）方式：DMA模块-> 模拟处理器来控制主存和色设备之间的数据交换
  1. 当遇见IO处理操作时，CPU不需要等待设备就绪
  2. 处理器向DMA模块发出IO命令，处理器可以执行其他工作，DMA模块负责传输全部数据
  3. 数据传送结束后，DMA中断，通知处理器执行中断程序切换进程（CPU不参与数据传送）

DMA周期窃取：

- 当DMA和CPU同时经总线访问内存时，CPU总是将总线的占有权让给DMA一个或者几个主存周期
- 周期窃取对延迟CPU和主存的数据交换影响不大
  - CPU大部分事件和缓存交换数据，直接访问内存较少
  - 数据传送过程不连续不规则

![image-20211020170759991](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E7%9B%B4%E6%8E%A5%E5%AD%98%E5%82%A8%E5%99%A8%E8%AE%BF%E9%97%AEDMA.png)

**IO通道**：又称为通道控制器、IO处理器，设备管理器包含自身专用的处理器和通道程序

- IO指令不再由处理器执行，而是存在主存中，由设备控制器中的IO通道包含的处理器执行
- 四级连接模型：处理器、通道、控制器，设备

**带有局部存储器的IO通道**：内部有存储的IO设备

- 类似于一台自治的小型计算机
  - IO指令存储自带局部存储器，并由IO通道的处理器执行
- 可以控制大量的IO设备，同时最小化CPU的干涉
- 常用于交互式中断通信，负责包括控制终端在内的大部分任务

**IO通道的IO流程**：

- CPU在遇到I/O请求，组织通道程序，放置通道程序地址字CAW，启动指定的IO通道
- 启动成功后，IO通道从CAW获取通道程序，开始控制IO设备进行操作，CPU处理执行其他任务（CPU、通道并行工作）
- IO操作完成后，IO通道发出中断，CPU停止当前工作，从通道程序状态子CSW获取通道执行状态，处理IO操作结束事件

### 4.6 IO和总线

总线：用来解决IO速度和CPU不匹配的问题

几种总线模型：

- 单总线模型：所有的设备部件通过一条总线连接

- 三级总线模型：

  - 主存和缓存之间通过主存总线连接
  - CPU和缓存之间使用一个局部总线
  - 主存总线和扩展总线上的IO设备通过扩展总线接口连接
  - 优点：主存和IO之间的数据传送、处理器内存活动分离，支持更多的IO设备
  - 缺点：不适合IO设备数据传输速率相差太大的情况

  ![image-20211020193433765](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E4%B8%89%E7%BA%A7%E6%80%BB%E7%BA%BF%E6%A8%A1%E5%9E%8B.png)

- 南桥和北桥模型：

  - 北桥：主存控制器，和主存通过存储总线连接，和CPU通过处理总线相连
  - 南桥：IO控制器，和其他的外部设备的总线连接
  - 南桥北桥之间有一个桥间接口连接

  ![image-20211020193714182](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E5%8D%97%E6%A1%A5%E5%8C%97%E6%A1%A5%E6%A8%A1%E5%9E%8B.png)

- 基于通道的服务器总线模型：

  - IO通道下面管辖多个IO控制器，IO控制器管辖多个设备
  - 主存总线和IO通道、CPU和主存相连

  ![image-20211020193954797](https://gitee.com/Jia_bao_Li/img/raw/master/img/IO%E9%80%9A%E9%81%93%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%80%BB%E7%BA%BF%E6%A8%A1%E5%9E%8B.png)

### 4.7 IO软件

#### 4.7.1 IO软件的分层架构

IO软件设计需要考虑：（通用无关性，高效性）

- 设备无关性：编写访问文件的程序和设备无关
- 出错处理：底层软件处理的错误不让高层软件感知
- 同步/异步传送：支持阻塞和中断两种工作方式
- 缓冲技术：建立数据缓冲区，提高吞吐率

![image-20211020194859153](C:\Users\jiabao\AppData\Roaming\Typora\typora-user-images\image-20211020194859153.png)

#### 4.7.2 IO中断程序设计

- 位于操作系统底层，与硬件设备密切相关，和系统其余部分尽可能少发生联系
- 进程请求IO操作时，通常被挂起，直到数据传输结束产生IO中断，操作系统接管CPU转向中断处理程序
- 设备向CPU发起中断请求，CPU响应请求并转入中断处理程序

处理流程：

- 检查设备状态寄存器的内容，判断中断发生的原因，根据IO操作的完成情况进行相应的处理
  - 如果数据传输错误，向上层软件报告出错信息，并实施重新执行
  - 如果正常结束，唤醒等待传输的进程，使其转换为就绪态重新执行
  - 如果有等待传输的IO命令，通知相关软件启动下一个IO请求

#### 4.7.3 设备驱动程序

**驱动程序的特点：**

- 包含与设备密切相关的所有代码（数据处理传输、数据的读写）
- 从独立于设备的软件中接收并执行IO请求
  - 把用户提交的逻辑IO转换为物理的IO操作并执行
  - 检测设备是否正确执行，管理数据缓冲区，进行必要的纠错处理

**驱动程序的功能：**

- 设备初始化
  - 设备初次启动或设备传输数据时，预置设备和控制器以及通道的状态
- 执行设备驱动
  - 启动设备，进行数据传输
  - 对于通道方式，负责生成通道指令和通道程序，启动通道工作
- 调用执行中断处理程序
  - 处理设备和控制器以及通道发出的各种中断

**驱动程序的层次分类：**

每个设备驱动程序只处理一种设备或一类紧密相关的设备

- 整体驱动程序：直接向操作系统提供接口控制硬件
  - 适用于功能简单的驱动
  - 效率较高，但是不容易迁移，代码较为复杂
- 分层驱动程序：将驱动程序分为多层，放在栈中，IO请求执行时，先执行栈顶的驱动程序，栈顶驱动可以直接处理请求或者向下调用更底层的驱动程序完成请求
  - 适合功能复杂、重用性要求高的驱动
  - 结构清楚，便于移植，会增加一部分系统开销（调用栈，多次调用）

#### 4.7.4 独立于设备的IO软件

执行适用于所有设备的常用的IO功能，并向用户层软件提供一致性的接口，这一IO软件的实现通常操作系统来实现

**功能**：

- 设备命名：通过路径名寻址设备
- 设备保护：检查用户是否有权访问所申请的设备
- 提供和设备无关的数据单位：字符数量、块大小
- 缓冲技术：传输速率改善
- 设备分配和状态跟踪：分配不同类型设备并跟踪设备的状态
- 错误处理和报告：驱动程序无法处理的错误需要报告给这一层软件

#### 4.7.5 用户空间的IO软件

库函数：一部分IO软件使用库函数实现，放在操作系统内核之外，运行时和应用程序链接

虚拟设备软件：用一类设备模拟另外一类设备的仿真IO软件，如手机模拟器这一类虚拟设备软件

### 4.8 IO缓冲区

目的：

- 解决CPU和设备之间速度不匹配的矛盾
- 协调逻辑记录大小和物理记录大小不一致的问题（磁盘扇区大小和块大小不一致）
- 提高设备和CPU的并行性
- 减少IO操作对CPU的中断次数
- 放宽CPU对中断响应时间的要求

IO缓冲区：在内存中开辟的存储区，专门用于临时存放IO操作的数据

缓冲区的操作流程：

- 写操作：将数据送至缓冲区，直到装满或者需要写出时会将缓冲区内容写回设备
- 读操作：系统将设备的物理记录读取至缓冲区，然后根据请求从缓冲区读取需要的数据传送给进程

#### 4.8.1 单缓冲技术

操作系统在主存中开设一个缓冲区

输入：

- 将设备数据读取到缓冲区，系统将缓冲区数据传送至用户应用程序，传输完毕之后应用程序开始处理数据，在应用程序处理数据时，可以继续从设备读取数据到缓冲区

输出：

- 应用程序将数据传输到缓冲区，系统将数据写回到设备，等数据写回完成之后，继续传输数据到缓冲区

![image-20211020210525232](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E5%8D%95%E7%BC%93%E5%86%B2%E6%8A%80%E6%9C%AF.png)

#### 4.8.2 双缓冲技术

操作系统在主存中开设了两个缓冲区。

输入：

- 设备先将数据传输到缓冲区1，系统从缓冲区1把数据传送到用户去给应用程序使用，在将缓冲区传递给应用程序的同时，设备可以将数据传送到缓冲区2

输出：

- 应用程序将数据从用户传送到缓冲区1，系统将缓冲区1的内容写回设备，于此同时，应用程序可以继续传输数据到缓冲区2

![image-20211020210602254](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E5%8F%8C%E7%BC%93%E5%86%B2%E6%8A%80%E6%9C%AF.png)

#### 4.8.3 多缓冲技术

操作系统在主存中开设了一组缓冲区，每个缓冲区有指向下一个缓冲区的指针，构成循环缓冲

- 解决设备和进程速度不匹配问题
- 是系统公共资源，提供给进程共享并由系统统一分配和管理

![image-20211020210655346](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E5%A4%9A%E7%BC%93%E5%86%B2%E6%8A%80%E6%9C%AF.png)



### 4.9 独占式设备

独占设备：只能由一个进程独占式使用

共享设备：可以由多个进程同时使用的设备

#### 设备独立性

用户通常不指定物理设备，而是指定逻辑设备，使得用户作业和物理设备分离开来，建立逻辑设备和物理设备之间的映射

#### 设备分配的数据结构

设备类表：

- 每类设备对应设备类表中的一个位置
- 设备类，总台数，空闲台数，设备表起始地址等

设备表：

- 每类设备下面有一个设备表，登记这一类设备下有多少个设备
- 物理设备名、逻辑设备名、占有设备的进程好、是否分配、好坏标志等

### 4.10 磁盘

盘片，磁道，轴，柱面，移动臂，读写磁头

![image-20211020222450713](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E7%A3%81%E7%9B%98%E7%BB%93%E6%9E%84.png)

![image-20211020222512702](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E7%A3%81%E7%9B%98%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%86%99.png)

![image-20211020222532464](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E7%A3%81%E7%9B%98%E8%AE%BF%E9%97%AE%E8%AF%BB%E5%8F%96%E6%97%B6%E9%97%B4.png)

#### 磁盘调度

移动臂调度：

调度策略：

- 先入先出策略：公平策略，效率较低
- 最短查找时间优先：存在饥饿现象
- 扫描算法：
  - 单向扫描，存在空转一次的情况（移动臂回调不服务
  - 双向扫描：每次扫描都查找最近的IO请求进行处理
  - 电梯调度：无请求不移动，每次选择移动方向最近的柱面移动，如果当前方向没有请求，提前改变方向

旋转调度：

- 循环排序：优化IO请求排序，最少旋转圈数完成同一柱面的访问请求
- 优化分布：通过信息在存储空间的排列方式减少旋转延迟

### 4.11 虚拟设备SPOOLing系统

使用一类物理设备模拟另一类物理设备的技术

示例：

- 内存卡模拟磁盘
- 块设备模拟字符设备
- 输入输出重定向

#### 4.11.1 SPOOLing系统

为存放输入数据和输出数据，系统在磁盘上开辟输入井和输出井

- 井用来缓冲的存储区域

组成：

- 预输入程序：数据从输入设备传送到磁盘输入井
- 缓输出程序：将数据从磁盘输出井传送到输出设备
- 井管理程序：控制作业和井之间的数据交换

作用：

- 预输入：操作系统将作业需要的输入数据成批从输入设备上预先输入至磁盘的输入缓冲区暂存
  - 调度作业执行时，作业使用数据不必再启动输入设备，从磁盘的输入缓冲区读取即可
- 缓输出：作业不启动输入设备，只是将输出数据暂存到输出缓冲区
  - 作业执行完毕后，操作系统成批输出

优点：

- 设备利用率提高，作业运行时间也会缩短，每个作业都感觉各自拥有所需要的独占设备

![image-20211020220059493](https://gitee.com/Jia_bao_Li/img/raw/master/img/SPOOLing%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84.png)

![image-20211020220237713](https://gitee.com/Jia_bao_Li/img/raw/master/img/SPOOLing%E7%B3%BB%E7%BB%9F%E4%BD%9C%E4%B8%9A%E7%8A%B6%E6%80%81.png)

![image-20211020220305746](https://gitee.com/Jia_bao_Li/img/raw/master/img/%E6%89%93%E5%8D%B0%E6%9C%BASPOOLing.png)

## 5 文件管理

### 5.1 文件系统和文件

**文件系统**：一种用于**持久性存储**的系统抽象

**文件**：文件系统中一个单元相关数据在操作系统中的抽象

文件块：用来保存文件属性（名称、类型、位置、大小、创建者创建时间修改时间等等）、文件存储块的位置和偏移量等

### 5.2 文件系统功能

- 分配文件磁盘空间
  - 管理文件块：哪一块磁盘空间属于哪一个文件
  - 管理空闲空间：管理磁盘等存储介质的空闲空间
  - 分配空间的算法：决定怎么给一个文件分配空间
- 管理文件集合：
  - 定位文件及其内容
  - 命名：通过名字找到文件的接口
  - 最常见的管理：分层文件系统
- 保证安全性、持久性、可靠性
  - 分层保护数据的安全
  - 保持文件的持久，即使发生崩溃、错误或着受到攻击

### 5.3 文件描述符

<font color='red'>用来跟踪进程中打开/新建的文件的一种数据结构</font>，文件描述符本质是一个非负整数，读写文件就是通过操作这个文件描述符来进行的。每个进程拥有的文件描述符是有限制的1024个

- 操作系统为每个进程维护了一个打开文件表
- 文件描述符对应的就是文件表的索引，索引对应的是存储介质中所保存的文件属性等信息

元数据来管理打开文件：

- 文件指针：指向最近的一次读写位置，每个打开了这个文件的进程都指向这个指针
- 文件打开计数：记录文件打开的次数，当最后一个进程关闭了文件，允许将其从打开文件列表中移出
- 文件磁盘位置：换出数据访问信息
- 访问权限：每个程序访问模式和权限等信息

文件的读写其实就是从磁盘中（按照扇区（和文件块映射）读取）读取到操作系统中的buffer缓冲区，等到操作完毕之后再从buffer中写回到磁盘当中

文件访问模式：

- 顺序访问：最常用的，按照字节一次读取
- 随机访问：不常用，访问更快
- 根据内容访问：数据库本质上就是在根据索引内容的磁盘访问

多用户共享：

- 需要同步
- 打开文件的写入内容立即对其他打开同一文件的用户可见
- 共享文件指针允许多用户同时读取和写入

会话：文件从打开到关闭的过程称为一个会话

- 写入文件的内容只有文件关闭之后可见（写回磁盘）

### 5.4 目录

文件以目录方式组织起来，每个目录包含一张表，表存储的是名字和名字对应的文件头（块）对应的信息

层次名称空间：将文件分层管理

目录操作：

- 搜索文件
- 创建文件
- 删除文件
- 枚举目录
- 重命名文件
- 文件系统遍历一个路径

操作系统只允许内核模式下修改目录

### 5.5 文件别名

硬链接：

软链接：

### 5.6 文件系统种类

磁盘文件系统：文件存储再数据存储设备中，如磁盘

- FAT、NTFS是windows的磁盘文件系统
- EXT2/3/4是Linux的文件系统

数据库文件系统：文件根据特征可悲寻址

- winfs

日志文件系统：记录文件系统的修改/事件，类似于MySQL中的binlog二进制日志文件

- journaling file system

网络/分布式文件系统

- NFS、SMB、AFS
- 分布式文件系统存在的问题：一致性问题、安全性问题

特殊/虚拟文件系统